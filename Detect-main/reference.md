202 4 年全国大学生信息安全竞赛报告 

# 202 4 年全国大学生信息安全竞赛 

# 作品报告 

# 作品名称： 基于语言无关特征和  LLM  融合的开源组件投毒检测 

# 电子邮箱：  970913997@qq.com 

# 提交日期：  2024 -06 -05 202 4 年全国大学生信息安全竞赛报告 

# 填写说明 

1.  所有参赛 项目 必须为一个基本完整的设计。 作品报告书旨在能够清晰准确地阐述 

（或图示）该参赛队的参赛项目（或 方案 ）。 

2.  作品报告采用 A4 纸撰写。 除标题外， 所有内容必需为宋体、 小四号字、 1.5 倍行距。 

3.  作品报告中各项目说明 文字部分仅供参考，作品报告书撰写完毕后，请删除所有 

说明文字。 (本页不删除 )

4.  作品报告模板里已经列的内容仅供参考，作者可以在此基础上增加内容或对文档 

结构进行微调。 

5.  为保证网评的公平、公正，作品报告中应避免出现作者所在学校、院系和指导教 

师等泄露身份的信息。 202 4 年全国大学生信息安全竞赛报告 

# 目 录

## 摘 要 ................................ ................................ ................................ .................. 1

## 第一章  作品概述  ................................ ................................ .............................. 3

1.1  背景分析  ................................ ................................ ................................ ................................ .....  3

1.2  相关工作  ................................ ................................ ................................ ................................ .....  4

1.3  特色描述  ................................ ................................ ................................ ................................ .....  6

1.3.1  跨语言恶意代码的共同训练  ................................ ................................ ........................  6

1.3. 2 多种开源软件供应链攻击的联合研究  ................................ ................................ ........  7

1.3. 3 创新性 的爬包处理  ................................ ................................ ................................ ........  8

1.3. 4 语言无关的特征  ................................ ................................ ................................ ............  9

1.3. 5 树形学习算法的性能评估  ................................ ................................ ..........................  10 

1.3. 6 真实世界的评估  ................................ ................................ ................................ ..........  10 

1.3.7  大模型应用  ................................ ................................ ................................ ..................  11 

1.4  应用前景分析  ................................ ................................ ................................ ...........................  11 

1.4.1  跨语言检测的潜力  ................................ ................................ ................................ .......  11 

1.4.2  机器学习算法的优化  ................................ ................................ ................................ ...  12 

1.4.3  特征集的扩展  ................................ ................................ ................................ ...............  12 

1.4.4  结合作者自动分析  ................................ ................................ ................................ .......  12 

1.4.5  大模型选择  ................................ ................................ ................................ ..................  12 

## 第二章  作品设计与实现  ................................ ................................ ...............  14 

2.1  原理综述  ................................ ................................ ................................ ................................ ..  14 

2.2  数据处理  ................................ ................................ ................................ ................................ ..  15 

2.3  算法选择与调整  ................................ ................................ ................................ ......................  16 

2.4  特征提取  ................................ ................................ ................................ ................................ ..  26 

2.5  模型训练和评估  ................................ ................................ ................................ ......................  29 

2.6  交叉验证  ................................ ................................ ................................ ................................ ..  31 

2.7  大语言模型复筛  ................................ ................................ ................................ ....................  31 

## 第三章  作品测试与分析  ................................ ................................ ...............  33 

3.1  测试方案  ................................ ................................ ................................ ................................ ..  33 

3.2  测试设备  ................................ ................................ ................................ ................................ ..  34 

3.2.1  开发环境  ................................ ................................ ................................ .......................  34 

3.2.2  环境配置  ................................ ................................ ................................ ......................  34 

3.3  数据集处理  ................................ ................................ ................................ ..............................  35 

3.3.1  建立本地存储库  ................................ ................................ ................................ ...........  35 

3.3.2  特征提取  ................................ ................................ ................................ ......................  37 

3.4  模型训练与测试  ................................ ................................ ................................ ......................  39 

3.4 .1  环境配置  ................................ ................................ ................................ ......................  39 

3.4 .2  模型训练  ................................ ................................ ................................ ......................  40 

3.4.3  大语言模型测试  ................................ ................................ ................................ ..........  42 202 4 年全国大学生信息安全竞赛报告 

3.4 .4  真实环境测试  ................................ ................................ ................................ ..............  44 

3.5  结果与分析  ................................ ................................ ................................ ..............................  45 

3. 5.1  模型训练结果与分析  ................................ ................................ ................................ ..  45 

3.5.2  大语言模型测试结果与分析  ................................ ................................ ......................  47 

3. 5.3  真实环境测试结果与分析  ................................ ................................ ..........................  49 

3. 5.4  模型对比分析  ................................ ................................ ................................ ..............  52 

3.6  自动化工具的实现  ................................ ................................ ................................ ..................  53 

## 第四章  创新性说明  ................................ ................................ .......................  57 

4.1  创新性方式进行爬包处理  ................................ ................................ ................................ .......  57 

4.2  提出语言无关的特征  ................................ ................................ ................................ ...............  57 

4.3  提出多种开源软件供应链攻击进行联合研究  ................................ ................................ .......  58 

4.4  引入大语言模型  ................................ ................................ ................................ ......................  59 

## 第五章  总结  ................................ ................................ ................................ ...  61 

## 参考文献  ................................ ................................ ................................ .........  63 202 4 年全国大学生信息安全竞赛报告    

> 第1页共64 页

# 摘 要

现代软件开发重度依赖开源组件，而开源代码暴露出越来越多的安全问题，特别 

是攻击者通过在开源组件中进行投毒恶意代码来进行的软件供应链攻击。 随着 Python 

和JavaScript 编程语言的流行 ，包管理平台如 PyPI 和npm 频繁 成为攻击目标。攻击者 

在其中发布包含恶意代码的开源组件包来实施攻击行为，例如敏感信息窃取、投放木 

马病毒等。因涉及复杂的恶意行为模式，此类攻击的检测具有很大挑战。 

本文通过构造编程语言无关的代码特征， 融合机器学习模型和大语言模型 （LLM ）

来对恶意代码进行识别，提出一种智能化的自动恶意包检测与分析方法。该方法主要 

包括以下步骤： （1）特征提取，从软件包中提取编程语言无关的 代码特征 ，构建训练 

特征集来训练机器学习模型； （2）使用机器学习模型进行结果分类判断初筛，对报告 

为恶意的软件包进行进一步验证；（ 3）利用大语言模型强大的代码理解能力和自然 

语言生成能力，对软件包的最终恶意性进行确认，并给出恶意性的理由。 

本文利用语言无关的特征和多种机器学习算法 （如决策树、 随机森林和 XGBoost ），

在JavaScript 和Python 生态系统中进行跨语言训练和评估，旨在捕捉恶意包的共性。 

本文结合 Backstabber's Knife Collection (BKC)  数据集中的恶意包样本和从 PyPI 

与npm 中收集的良性包样本，构建了一个跨语言的特征集，用于模型的训练和调优。 

在特征提取方面，本文提出了 141 个语言无关的特征，包括字符串和标识符的熵值特 

征、文件扩展名的使用情况、钩子函数的使用情况等。本文通过贝叶斯优化器结合 5

折交叉验证， 优化了模型的超参数， 确保了模型的精度和稳定性。 在实际环境测试中， 

本文设计并实现了一种自动化框架，用于定期监控 npm 和PyPI 上最新更新和上传的软 

件包，并缓存软件包到本地。该框架通过并行处理、状态管理、异常处理和文件监控 

等技术，确保高效地收集和管理软件包。将包首先进行特征处理，然后使用机器学习 

算法预测包的恶意性， 最后借助 大语言模型进行假阳性结果清除，进一步提高了检测 

精度，省去了人工筛查的负担。 

实验 结果显示，跨语言模型在检测恶意包方面比单语言模型表现更好，精确度更高； 

而且大语言模型能够精准地识别恶意代码。在实际场景下，通过扫描新上传的 npm 包

和PyPI 包，成功检测并验证了 134 个以前未知的恶意软件包（其中 38 个针对 npm ，96 个202 4 年全国大学生信息安全竞赛报告    

> 第2页共64 页

针对 PyPI ），这些软件包目前已从 PyPI 和npm 平台上被移除 。相比于华为的最新研究 

Donapi [2] ，本文具有 更高的跨平台与跨语言兼容性 ，同时本文的模型在 控制实验和真 

实环境实验 中都得到了验证、 利用多样化的数据集进行模型训练， 使得相较于 Donapi ，

本文方法在实际环境中更加有效、在处理各种恶意软件行为时更加灵活和准确，能在 

短时间内检测出 。相较于现有模型如 Bandit4mal 、OSSGadget -backdoor 等恶意代码检测 

工具 误报率下降，准确率升高 。相比于单纯使用大语言模型（ LLM ）的最新研究成果 

[3] ，本文有 更广泛的适用性和更低的假阳性 。本作品的创新之处在于提出了一种自动 

化的的恶意软件包投毒检测方法，通过跨语言训练和评估，克服了样本稀缺的问题。 

再通过详细的特征选择、模型优化以及和大语言模型相结合，显著提高了恶意包检测 

的准确性和效率。未来，本方法有望扩展到其他语言环境（如 Ruby 和PHP ），进一步提 

升开源软件生态系统的安全性。 

关键词 ：开源软件供应链，恶意包检测，语言无关特征，机器学习，大语言模型 202 4 年全国大学生信息安全竞赛报告    

> 第3页共64 页

# 第一章  作品概述 

# 1.1  背景分析 

从大型公司到独立开发者，当前的软件 往往通过 大量消费开源软件包 作为通用 

的生产方式。 随着如  python 、javasc ript  等编程语言的普及， 大量针对 特定 编程语言 

生态系统的包仓库和包管理器被创建 与优化 ，不断 简化 着下游用户对开源软件 

（OSS ）的使用。 所谓 包仓库（例如  PyP I、Npm ）就是可以查询以检索实现特定任 

务的软件包的公共数据库 ，而 包管理器 就是帮助客户在 客户端自动解决并安装所需 

的软件包及其依赖项 的有效工具 。

然而， 这些机制 在促进了软件模块化并提高了实现速度 的同时 ，也使得不法的 

恶意用户开始 以软件供应链的薄弱点为切入，进行 恶意软件的大规模传播。开源软 

件供应链的攻击面很大，攻击者可以利用多种攻击向量来进行开源软件供应链攻 

击。鉴于大多数公司都使用开源软件，提高软件供应链的安全性已成为社区和国家 

安全的优先事项。 

在 Npm  和 PyPI  生态系统中，恶意用户通过发布包含恶意代码的开源软件包传 

播恶意软件的情况时有发生。例如， 2018  年，流行的  Npm  包 Event -Stream  被注入 

恶意代码，试图窃取比特币； 2021  年，ua -parser -js  包被篡改，植入了加密货币挖矿 

软件。在  Py PI  上，恶意包  colourama  和 python 3-dateutil  更是 通过拼写错误和模仿 

真实包名来诱骗用户下载 而大量 窃取 了用户的 敏感信息。 不断产生的恶意事件在提 

醒着维护网络安全的工作者们 维护开源软件供应链安全的必要性 与迫切性 。202 4 年全国大学生信息安全竞赛报告        

> 第4页共64 页
> 图1-1开源新项目过去 4年的增长率

当下， 应对开源软件供应链攻击的一种 常用 方法是 通过 检测 分析 包仓库中 下载 

的软件包中是否存在恶意行为 并及时上报来实现对恶意代码传播的有效防御 。最近 

的研究提出了用于软件供应链安全以检测恶意软件包的机器学习（ ML ）技术。通过 

自动化恶意包检测，利用机器学习算法（如随机森林、支持向量机、深度学习等） 

来分析包的元数据、依赖关系、代码特征和发布历史，以检测潜在的恶意行为。 

纵然机器学习方法快速便捷，但现实环境也带来了技术上的挑战 --样本稀缺 使得 

在软件供应链安全中应用机器学习技术 无法高效准确的识别恶意软件包 。这种稀缺 

限制了模型的训练数据量和代表性，导致模型性能受限、偏差问题突出以及特征学 

习受限 等多方面问题 。此外，验证和评估方面也面临困难， 使得 基准数据集和验证 

手段缺乏可靠 性。

# 1.2  相关工作 

Sejfia  等人在  Practical Automated Detection of Malicious npm Package [4] 一文中提 

出了一种结合代码复现器和简单克隆检测器的监督学习方法，用于自动检测  Npm 

中的恶意软件包。 

其提出了一个名为  Amalfi  的自动化方法，用于检测  Npm  中的恶意软件包版 

本，旨在尽快发现潜在的恶意版本并报告给人工审计员进行处理。为了实现这一目 202 4 年全国大学生信息安全竞赛报告    

> 第5页共64 页

标，他们将三种互补的技术组合到一个系统中： 

机器学习分类器：利用已标记的恶意和良性软件包示例进行训练，提取记录包 

使用的  API  变化和包元数 据的特征。这些分类器学习区分典型的（因此最可能无害 

的）特征变化和非典型的（因此可疑的）特征变化。 

重现器：从源代码重新构建一个软件包，并将结果与注册表中发布的版本进行 

比较。如果能够从源代码中重现软件包版本，则表明该版本是良性的。 

克隆检测器：查找已知恶意软件包的（近乎）文本相同的副本。这有助于消除 

误报。 

他们的特征选择受到了一些观察的启发，即恶意软件包往往利用  JavaScript  语

言、底层平台 和 Npm  包管理器的独特功能，尤其是当软件包突然开始使用以前从未 

使用过的功能时。通过训练分类器，并使用特征提取和聚类技术，他们能够有效地 

检测和区分恶意软件包。文章还提到了他们实验的结果，显示了他们的方法的有效 

性和效率，以及他们对模型进行连续改进的能力。 

Garret  等人在  Detecting suspicious package updates [5] 一文中应用异常检测方法来 

识别  Npm  生态系统中的恶意更新。 

他们的用例将  JavaScript  包的一个版本与以前的版本进行比较，以检测恶意更 

新。具体方法如下： 

基于异常检测的自动化方法：文章的基本假设是正常更新的频率比可疑更新更 

高，因此可以根据这种正常行为建立模型。他们从包的元数据和源代码中提取特 

征，包括分析包的  JavaScript  源文件，识别新文件、新依赖和新挂钩脚本的存在， 

并使用二进制表示每个特征的存在或变化。 

建立正常行为模型：利用采集到的数据建立了正常行为模型，并使用  k-means 

聚类技术将包的更新数据进行聚类。对于不同类型的更新（补丁、次要和主要）， 

他们创建了不同的检测模型，并分别使用了不同数量的聚类。 

验证模型：使用测试数据集验证模型，将每个更新分配给现有聚类，并将更新 

视为可疑，如果它不在聚类边界内。如果测试数据集中的新更新被分配到聚类并且 

距离聚类中的最远数据点更远，则认为该更新是可疑的。 

最终，该方法旨在自动检测  Npm  中的恶意软件包更新，并对可疑更新进行进一 

步审查。 202 4 年全国大学生信息安全竞赛报告    

> 第6页共64 页

An Empirical Study of Malicious Code In PyPI Ecosystem [7] 一文中 创建了最大的公 

开可用的  PyPI  恶意软件包数据集。 并实现 自动分类框架 ，对恶意代码进行分类， 

以帮助检测。 全面 分析 了恶意代码的特征、行为、传播和影响 ：大约  74.81%  的恶 

意软件包通过源代码安装进入终端用户项目。许多恶意软件包在被报告后仍然在 

PyPI  镜像中存在。 突出了  PyPI  环境中恶意软件传播的危害性 

Bad Snakes: Understanding and Improving Python  Package Index Malware 

Scanning [9] 首次在统一数据集上比较了现有的自动化  Python  恶意软件检测工具，提 

供了各工具的假阳性率和真阳性率数据。 提出了改进检测能力和加强安全研究人员 

与软件仓库管理员合作的建议。 得出 目前的自动化恶意软件检测工具还不能满足 

PyPI  等开源软件包管理平台的 需求的真实结论。 

# 1.3  特色描述 

1.3.1  跨语言恶意代码的共同训练 

在课题组进行针对 攻击者攻击供应链的研究时，发现许多开源软件供应链攻击 

者往往 使用类似的策略和技术来进行攻击， 我们认为通用针对多种语言的同种攻击 

手段 能有效 地绕过安全检测和防御机制。例如，攻击者可能会使用相似的安装脚 

本、混淆字符串或  URL  来隐藏恶意行为并欺骗用户。同时，攻击者会选择应用场 

景被广泛应用于  Web  开发、数据科学领域等大量日常使用领域，因此选择的攻击 

语言也有定向性的特点。 

因此， 针对开源软件供应链的攻击，尤其是那些跨语言使用相似技术和策略的 

攻击 ，我们采用跨语言的安全静态分析方式。通过 针对不同语言的包管理器进行静 

态分析，检查依赖关系和安装脚本中的异常行为 来捕捉恶意代码包。 

采用 集成多语言支持 的方式，通过 扩展功能模块 ，在现有静态分析工具中，增 

加对其他编程语言的支持。改进工具，使其能够在跨语言项目中进行一致的分析。 

在本课题中，我们通过 分析包含  Python  和 JavaScript  代码的 不同代码包 ，通过机器 

学习的训练方式寻找两者的共性，实现 统一检查和报告安全问题。 202 4 年全国大学生信息安全竞赛报告      

> 第7页共64 页
> 图1-2跨语言实现流程图

1.3. 2 多种开源软件供应链攻击的联合研究 

针对攻击者采用类似方式共机不同语言的共性，我们采取  JavaScript  和 Python 

两种语言的开源软件供应链攻击进行联合研究。虽然  JavaScript  和 Python  的语法 

和生态系统存在差异，但在恶意软件攻击中常见的特征和行为模式可能是相似的， 

比如安装脚本、混淆字符串和  URL 。通过共享这些特征，可以在两种语言之间进行 

特征转移学习，利用已有的知识来弥补样本稀缺问题。同时， JavaScript  和 Python 

社区丰富的开源软件包和数据集。联合研究以促进两个社区之间的数据集和模型共 

享，扩大训练数据的规模和多样性，提高模型的泛化能力和检测效果。更重要的是 

从恶意攻击的角度来看，许多恶意软件攻击并不局限于单一语言或平台，而是跨越 

多种技术栈和环境。因此，综合研究可以提供更全面的解决方案，覆盖多个领域的 

安全问题，从而更好地保护软件供应链的安全性。 

1.  跨语言数据集训练：将  JavaScript  和 Python  数据集结合训练模型，提高了模型的 

泛化能力，更有效地检测不同语言中的恶意代码。 

2.  多种分类算法比较：详细评估了不同分类算法在单语言和跨语言数据集上的性 

能，通过比较精度、召回率、 F1 -score  和准确率，确定  XGBoost  在各个场景中的最佳 

平衡性能。 

3.  增强的小数据集处理方法：采用  5 折交叉验证并重复十次的方法处理小数据集， 202 4 年全国大学生信息安全竞赛报告    

> 第8页共64 页

利用分层抽样技术保持数据集中良性和恶性样本的比例，提高了评估的稳定性和可 

靠性。 

详细的性能指标报告：提供了详尽的模型性能指标，展示了模型的检测能力， 

并揭示了不同算法在实际应用中的优劣。 

1.3. 3 创新性 的爬包处理 

利用并行处理、多线程和文件监控机制，从  npm  注册表获取变更数据，并自动 

下载新软件包。 

1.  高效并行处理 :

利用  concurrent -couch -follower  库和  ThreadPoolExecutor  实现并行数据获取和处 

理，提高了数据处理速度和效率。 

2.  自动化流程 :

通过  watchdog  库实时监控文件系统变化，自动触发下载任务，实现了从数据获 

取到文件下载的全自动化流程，减少了人工干预。 

3.  状态管理和重复处理避免 :

使用状态文件  processed_files.txt  管理已处理文件，避免了重复处理，节省了时 

间和资源。 

1.  # 状态文件路径 

2.  STATUS_FILE_PATH  = 'processed_files.txt' 

3.  print ("processed_files.txt  文件保存处理过的  JSON  文件， 再次运行程序将不处理这些  JSON  文

> 件")

4. 

5.  # 读取已处理文件列表 

6.  processed_files  = set() 

7.  if  os.path.exists(STATUS_FILE_PATH): 

8.  with  open(STATUS_FILE_PATH,  'r' , encoding= 'utf -8' ) as  f: 

9.  processed_files  = set(f.read().splitlines()) 

4.  健壮的异常处理机制 :

在下载过程中设置最大重试次数  MAX_RETRIES ，确保在网络不稳定时依然能 

够完成下载任务，提高了系统的可靠性。 

1.  # 线程池大小 

2.  MAX_WORKERS  = 5 # 解析  json  文件线程数 

3.  FILEDOWN_MAX_WORKERS  = 10  # 下载文件线程数 202 4 年全国大学生信息安全竞赛报告 

第9页 共 64 页

4. 

5.  print (f "线程数：处理  JSON （{Fore.GREEN }{MAX_WORKERS}{Style.RESET_ALL} ）,下载文件 

（{Fore.GREEN}{FILEDOWN_MAX_WORKERS}{Style.RESET_ALL} ）")

6. 

7.  # 重试次数 

8.  MAX_RETRIES  = 3

9. 

10.  # 状态文件锁 

11.  status_file_lock  = threading.Lock() 

12. 

13.  def  process_json_file(file_path): 

5.  灵活性和扩展性 :

该方法可以根据需要调整并行处理的并发数和重试次数，适应不同规模和网络 

条件下的数据处理需求。 

图 1-3

1.3. 4 语言无关的特征 

1.  提出语言无关的特征： 

通过结合已有研究成果和 专业 知识，提出了一个包含  141  个语言无关特征的  特

征集合，这些特征适用于不同编程语言的环境，为跨语言恶意软件检测提  供了基 

础。 

2.  特征选取的合理性： 202 4 年全国大学生信息安全竞赛报告    

> 第10 页共64 页

这些特征基于通用性、结合 专业 知识、多样化的特征类型以及统计分布分析 

来选取，确保了模型的准确性和全面性。 

1.3. 5 树形学习算法的性能评估 

评估树形学习算法的性能：对多种树形学习算法（决策树、随机森林、 

XGBoost ）在  JavaScript  和 Python  环境下进行了评估，发现  XGBoost  在单语言和跨 

语言模型中表现最佳。   

> 图1-4 XGBoast 模型流程图

1.3. 6 真实世界的评估 

真实世界的评估：通过分析连续  10  天上传到  Npm  和 PyPI  的软件包，进行了实 

际环境中的模型评估。 

1.  数据收集和处理：收集并处理在一段时间内上传到  Npm  和 PyPI  的软件包， 

提取特征信息。 

2.  分类模型应用：使用训练好的模型对收集到的软件包进行分类。 

3.  手动审核：对被分类为恶意的软件包进行了手动审核，验证真阳性和假阳 

性。 

4.  结果报告：报告发现的恶意软件包数量及对应的精确度和手动审核的工作 

量。 202 4 年全国大学生信息安全竞赛报告      

> 第11 页共64 页
> 图1-5真实世界评估

1.3.7  大模型应用 

本作品通过构造提示词、建立答案空间与输入空间之间的映射，测试前缀式与完 

形填空式训练效果，训练有效提示词，从而在输入段添加额外文本，优化预训练语言 

模型的知识利用，提升恶意代码定位的有效性。针对  ChatGPT 、文心一言、 Kimi  等主 

流大语言模型（ LLM ），本文将其与恶意代码检测相结合，通过比较不同模型的识别 

能力，为网络安全工作者选择使用模型提供参考。作品特点如下： 

1.  提示词优化：通过构造提示词并进行训练，提升模型在恶意代码定位中的有效 

回答能力。  

> 2.

输入优化技术：在输入段添加额外文本，增强预训练语言模型的知识利用率。  

> 3.

多模型比较：测试和比较  ChatGPT 、文心一言、 Kimi  等不同大语言模型的恶意 

代码识别能力，提供选择参考。  

> 4.

通过比对不同大模型对恶意代码的识别能力为广大网安工作者提供在选择使用 

模型时的参考。 

# 1.4  应用前景分析 

1.4.1  跨语言检测的潜力 

研究表明，跨语言方法在检测  Npm  和 PyPI  中的恶意软件包方面是可行的。这 

为将来在其他语言环境下应用类似的方法打开了大门，例如  Ruby  和 PHP 。通过扩 202 4 年全国大学生信息安全竞赛报告    

> 第12 页共64 页

展到其他语言，可以进一步提高恶意软件检测的范围和效果，为更广泛的软件生态 

系统提供保护。 

1.4.2  机器学习算法的优化 

研究发现  XGBoost  在分类恶意和良性软件包时表现更好。未来的研究可以继续 

探索其他机器学习算法，并找到最佳的性能模型。通过对不同算法的比较和优化， 

可以进一步提高恶意软件检测的准确性和效率。 

1.4.3  特征集的扩展 

研究采用了简单但有效的特征集来区分恶意和良性软件包。未来的工作可以通过 

添加更多的特征来进一步细化模型，从而提高检测的精度和鲁棒性。例如，可以考 

虑添加与代码行为和结构相关的特征，以更全面地描述软件包的特性。 

1.4.4  结合作者自动分析 

研究者计划将机器学习分类器与对同一作者上传的软件包的自动分析相结合。通 

过分析与已确认恶意软件包相同作者相关联的软件包，可以进一步发现恶意软件， 

并及时采取措施进行处理，提高整个生态系统的安全性。 

1.4.5  大模型选择 

在恶意代码检测中引入大模型 （LLM ）为网络安全领域带来了新的前景和可能性。 

1.  提高检测准确性 

大模型具备强大的自然语言处理能力，通过学习海量数据，可以更准确地识别复 

杂的恶意代码模式。相比传统方法，大模型能更全面地理解代码上下文和行为，从而 

提高检测的准确性。 

2.  增强模型泛化能力 

通过跨语言训练和多模型比对，大模型能够在不同编程语言和环境中有效工作。 

其泛化能力使得它们在识别新型或变种恶意代码时表现更出色， 减少了因特定语言或 

平台带来的限制。 

3.  自动化与效率提升 

引入大模型的自动化工具可以持续监控和分析开源包仓库， 实时检测新上传的包。 

这不仅提高了检测效率，还能迅速响应和处理潜在威胁，减少人工审核的负担。 202 4 年全国大学生信息安全竞赛报告    

> 第13 页共64 页

4.  个性化和定制化 

未来， 大模型可以根据不同组织或项目的需求， 提供定制化的恶意代码检测服务。 

通过特定领域的训练数据优化模型，使其更适应特定的安全需求。 

5.  多模型协同与对比分析 

将多个大模型（ 如 ChatGPT 、文心一言、 Kimi ）进行对比分析，可以为网络安全 

工作者提供更全面的参考。在不同场景下选择最优模型，提高检测效果。 

6.  持续学习和更新 

大模型可以通过持续学习最新的恶意代码样本和攻击技术， 保持其检测能力的前 

沿。这种自适应能力确保了模型能够应对不断演变的网络威胁。 

7.  集成与扩展 

未来，大模型可以与现有的安全工具和平台深度集成，形成一个全面的安全生态 

系统。此外，这些模型还可以扩展到其他编程语言和开发环境，如  Ruby  和 PHP ，进 

一步增强开源软件生态系统的安全性。 

随着大模型在恶意代码检测中的应用不断深化，网络安全领域将迎来更高效、更 

准确的检测工具，显著提升开源软件生态系统的安全性。同时，通过多模型协同和持 

续优化，网络安全工作者将获得更强大的技术支持，以应对不断演变的网络威胁。 202 4 年全国大学生信息安全竞赛报告    

> 第14 页共64 页

# 第二章 作品设计与实现 

# 2.1  原理综述 

本课题的任务是 检测  Npm  和 PyPI  等不同语言 中的恶意包，为此，我们提出一 

种利用语言无关特征的检测方法，旨在捕捉  Npm  和 PyPI  中的恶意包的共性。这种 

方法允许在包含多种语言的数据集上训练模型，从而克服样本有限 的问题，主要遵 

循以下步骤： 

1.  构建数据集：使用  Backstabber's  Knife  Collection  (BKC )[1]  数据集中的恶 

意包样本，以及从  Npm  和 PyPI  中收集的良性包，构建了不平衡的数据集 

（恶意包占  10% ）。 

图 2-1 "Labelled Dataset" 

2.  选择特征：选择了  141  个语言无关的特征，包括字符串和标识符的特性、文 

件扩展名的使用情况、安装钩子的使用情况等，以捕捉恶意行为的模式。 202 4 年全国大学生信息安全竞赛报告      

> 第15 页共64 页
> 图2-2部分特征示意

3.  模型训练和评估：采用决策树 （DT ）、随机森林（ RF ）和  XGB 

（XGBoost ）三种树模型，分别在  JavaScript 、Python  和跨语言的数据集上 

进行训练和评估。 

4.  真实 环境测试：通过扫描新上传到  Npm  和 PyPI  的包，对这些模型进行 真实 

环境测试 ，并借助大语言模型实现更加高效和准确的恶意包检测 ,以验证模 

型在各个指标下的性能数据，根据结果调整参数。 

# 2.2  数据处理 

我们构建了一个包含良性和恶意包的标记数据集。鉴于在实际包存储库中，良 

性包的数量远远超过恶意包，我们创建了一个不平衡的数据集以反映这一现实。由 

于恶意包与良性包的确切比例尚不确定，我们采用了之前研究中推荐的  90~10  的良 

性包与恶意包的比例。 202 4 年全国大学生信息安全竞赛报告    

> 第16 页共64 页

恶意样本：  我们使用  BKC ，这是一个包含在流行包存储库中发现的恶意开源软 

件包的集合，由社区自愿贡献。值得注意的是，相当大一部分包与恶意软件活动有 

关（即包具有不同名称但包含相同的恶意行为）。因此，在  BKC  数据集中可能会遇 

到多个重复项。为了避免偏差，我们从数据集中删除重复项。我们将以下情况视为 

重复项： (1) 拥有多个版本的包， (2) 在 BKC  中被标记为活动一部分的包，以及 

(3) 在所考虑特征上具有相同值的包。在第一种情况下，我们只考虑最新版本。对 

于属于同一活动或具有相同特征值的包，我们只取一个样本。 

关于恶意行为，值得一提的是，我们的方法仅限于  BKC  中存在的那些行为，即 

反向  shell 、植入器、数据泄露、拒绝服务（ DoS ）和经济获利。 所以 额外的行为 

（例如，钓鱼活动）不在我们的范围之内。 

# 2.3  算法选择与调整 

（一）模型训练部分 

我们的主要目标是探索跨语言检测恶意包的可行性。如前所述，恶意包的数量 

预计远少于良性包。因此，我们寻找适合不平衡数据集的监督分类算法，这些算法 

不需要对数据集本身进行预处理。此外，为了更好地理解模型的性能，我们寻找能 

够提供可解释预测的算法。最后，考虑到所涉及的特征数量，我们仅考虑能够处理 

高维数据的学习算法。 

符合这些标准并且在最近的研究中表现最好的算法是决策树（ DT ）和随机森林 

（RF ）。在基于树的算法背景下，我们还考虑了  XGBoost （XGB ）算法， 接下来我 

们将对这三种机器学习的原理逐一介绍。 

a.  决策树（ CART ）

决策树是一种树状结构的模型，通过对数据进行分割，形成用于分类或回归的规 

则。决策树的构建涉及以下关键公式： 

信息增益（ Information Gain ）： 

决策树使用信息增益来选择最佳分割点， 信息增益衡量了数据分割前后不确定性 

的减少。信息熵（ Entropy ）的计算公式为： 202 4 年全国大学生信息安全竞赛报告    

> 第17 页共64 页

其中， 𝑝 𝑖 是类别 𝑖 在数据集 𝐷 中的概率。 

分割后的信息熵为： 

其中，∣ Dv ∣是属性 𝐴 取值为 𝑣 时数据集的大小。 

信息增益为： 

基尼指数（ Gini Index ）：基尼指数是另一种衡量不纯度的方法，计算公式为： 

属性 𝐴 的基尼指数为： 

sklearn  中决策树 模型采用的是  CART  算法 ，CART  是在给定输入随机变量  X 条

件下输出随机变量  Y 的条件概率分布的学习方法。 CART  构建决策树用的是二叉树结 

构，在每个叶节点上预测的是概率分布，也就是在输入给定的条件下输出的条件概率 

分布。 

CART  算法由以下两步组成： 

（1）决策树生成：基于训练数据集生成决策树，生成的决策树要尽量大； 

（2）决策树剪枝：用验证集对已生成的树进行剪枝并选择最优子树，这时用损失 

函数最小作为剪枝的标准。 

CART  决策树的生成就是递归的调用二叉树的过程。对回归树用平方误差最小化 

准则（ mse ）或绝对误差最小化准则（ mae ），对分类树用基尼指数最小化准则，进行 

特征选择，生成二叉树。 202 4 年全国大学生信息安全竞赛报告    

> 第18 页共64 页

算法中核心的构建决策树源码如下： 

1.  def  fit(self,  x,  y,  sample_weight=None,  check_input=True): 

2.  super().fit( 

3.  x, 

4.  y, 

5.  sample_weight=sample_weight, 

6.  check_input=check_input, 

7.  )

8.  return  self 

b.  随机森林（ Random Forest, RF ）

随机森林是一种集成学习方法， 通过构建多个决策树并将它们的预测结果进行平 

均或投票来提高模型的准确性和稳定性。 随机森林的核心思想是通过引入随机性来增 

强模型的泛化能力，并减少单个决策树的过拟合风险。 

随机森林的预测： 

其中， 是随机森林的预测结果， 𝐵 是树的数量， 𝑓 𝑏 (𝑥 )是第 𝑏 棵树的预测结果。 

随机森林的构建过程包括以下几个步骤： 

（1）Bootstrap  采样：从原始训练数据集中有放回地抽取多个子集，每个子集用 

于训练一棵决策树。 

（2）特征选择随机化：在每个决策节点上，随机选择一个特征子集，从中选择最 

优特征进行数据划分。 

（3）决策树生成：使用每个子集和特征子集生成决策树，通常不进行剪枝操作。 

（4）集成预测：对新样本进行预测时，将所有决策树的预测结果进行平均（回归 

任务）或多数投票（分类任务）。 

随机森林具有良好的泛化性能，能够处理高维数据和缺失值，并且在处理大规模 

数据时表现出色。然而，其计算复杂度较高，模型训练和预测速度较慢。 202 4 年全国大学生信息安全竞赛报告    

> 第19 页共64 页

算法中核心的构建随机森林源码如下： 

1.  def  fit(self,  X,  y): 

2.  self.trees  = [] 

3.  n_samples  = X.shape[ 0]

4.  for  _ in  range(self.n_estimators): 

5.  indices  = np.random.choice(n_samples,  n_samples,  replace=True) 

6.  X_sample,  y_sample  = X[indices],  y[indices] 

7.  tree  = build_tree(X_sample,  y_sample,  max_depth=self.max_depth) 

8.  self.trees.append(tree) 

c. XGBoost （Extreme Gradient Boosting, XGB ）

XGBoost  是一种基于梯度提升（ Gradient Boosting ）的集成学习方法，专注于通 

过逐步构建多个弱预测模型（通常是决策树）来提升整体模型的预测性能。 

XGBoost  在许多机器学习竞赛中表现优异，被广泛应用于各种实际问题中，如分 

类、回归和排序任务。其核心思想是通过优化损失函数和引入正则化项，增强模型 

的泛化能力，并提升计算效率。 

XGBoost  的构建过程包括以下几个步骤： 

（1）初始化模型：初始模型通常是一个简单的预测值（如用训练集中目标变量 

的均值），用来开始迭代过程。 

（2）计算残差：对于每个样本，计算当前模型的预测值与实际值之间的误差 

（残差）。残差表示当前模型的不足之处。 

ri  = yi  − y^i

（3）构建决策树：使用残差构建一个新的决策树。这个树的目标是学习残差， 

即预测模型需要改进的部分。 

（4）计算叶节点的输出值：对于每个叶节点，计算一个值来缩小该节点中样本 

的残差。这个值是通过最小化目标函数得到的。 

（5）更新模型：将新决策树的输出值加入到现有模型中，更新模型的预测值。 

y^i ← y^i + ηfm (xi )

（6）正则化：引入正则化项，防止过拟合。正则化项考虑了树的复杂度，包括 

叶节点数和叶节点值的平方和。 

（7）重复迭代：重复上述步骤，构建多棵树，逐步改进模型的预测能力。 202 4 年全国大学生信息安全竞赛报告    

> 第20 页共64 页

（8）停止条件：根据预定的停止条件（如达到最大树数或验证集误差不再减 

少）停止迭代。 

算法中的核心代码如下：                          

> 1. def fit(self, X, y):
> 2. y_pred =np.zeros_like(y)
> 3. for _in range(self.n_estimators):
> 4. gradient =self._compute_gradient(y, y_pred)
> 5. tree =self._fit_tree(X, gradient)
> 6. y_pred += self.learning_rate *tree.predict(X)
> 7. self.trees.append(tree)

针对不平衡的数据集，本研究选择使用  boosting  算法 训练上述分类器。原因有 

以下四点： 

（1）重点关注错误样本： Boosting  算法的核心思想是通过训练一系列弱分类器 

（或回归器），每个分类器都专注于修正之前模型的错误。在处理不平衡数据集 

时，由于少数类样本数量较少，这些样本容易被错误分类。 Boosting  算法通过重点 

关注这些错误样本，逐步提升对它们的分类能力，从而改善对于少数类的识别效 

果。 

（2）逐步提升性能： Boosting  算法是一种迭代的学习方法，每一轮迭代都会根 

据上一轮的错误情况来调整模型，使得模型能够逐步适应数据分布，减少错误分类 

的样本。在不平衡数据集中，由于少数类样本的重要性更高， Boosting  算法会更加 

关注这些样本，在每一轮迭代中不断提升对它们的分类能力。 

（3）样本加权和类别加权：在  scikit -learn  中，你可以使用类别权重参数 

（class_weight ）或样本权重参数（ sample_weight ）来平衡不同类别之间的重要性。 

这些参数可以让模型更加关注少数类样本，从而提高对于少数类的识别能力。 

Boosting  算法在这种情况下能够更好地利用样本和类别权重来调整模型，以适应不 

平衡数据集。 

（4）适应性强： Boosting  算法在迭代过程中会逐渐调整模型，使得模型能够更 

好地适应数据分布和样本特点。这种适应性能力使得  Boosting  算法在处理不平衡数 

据集时能够更加灵活和有效地提升模型性能。 202 4 年全国大学生信息安全竞赛报告    

> 第21 页共64 页

为了微调所选算法以解决分类问题，我们使用贝叶斯优化器（ BO ）结合  5 折交 

叉验证来找到最高精度的最佳超参数组合。我们选择精度作为目标函数，以减少误 

报的数量，即必须手动审查以确认分类的样本数量。考虑用于优化问题的精度值是 

通过  5 折交叉验证后获得的平均值。 

对于  DT  分类器，通过  BO  优化的超参数包括树的最大深度、最大特征数、分裂 

标准（即信息增益、基尼指数、对数损失）、叶子节点中的最小观测数以及分裂内 

部节点所需的最小样本数。对于  RF  分类器，除了  DT  的超参数外，我们还优化估计 

器的数量（即决策树的数量）和训练每棵树的最大样本数。最后，对于  XGBoost  分

类器，优化的超参数包括树的最大深度、估计器的数量、构建每棵树的特征子样本 

比例、学习率、最小分裂损失以及子节点中所需的最小海森矩阵和。 

（二） 软件包获取部分 

这一部分的目的是要可以实时获取最新更新的  npm  软件包，以满足“实时监测 

恶意软件包”的目标需求，以及便于对模型接入真实环境时进行新包测试，为此我 

们尝试了三种不同的思路。（以  npm  软件包为例） 

第一种是直接编写爬虫程序，直接从  npm  官网界面爬取在官网界面更新的  npm 

软件包，这一阶段我们设计和实现了一个自动化工具，用于定期监控  npm  官网上最 

新更新的包信息，并下载其软件包。该工具通过使用  playwright  库进行网页操作和 

多线程处理，确保高效地收集和管理数据。以下是算法选择与调整的具体步骤： 

1.  数据获取和处理： 我们首先使用  python  编写了一个脚本，该脚本利用  playwright 

库从  npm  官网获取最近更新的包信息，并将其保存为  CSV  文件。主要功能包 

括：启动浏览器并访问  npm  官网→获取最近更新的包信息，包括包名、发布时 

间等→判断是否存在重复项，避免重复处理。 

1.  

> def task():

2.  # 在这里编写想要定时运行的任务代码 

3.  print ("定时任务执行 ")

4.  df  = pd.read_csv( 'C:/Users/97091/Desktop/getgithub/file/result.csv' ,enc 

> oding= 'utf -8' )

5. 

6.  # 获取当前时间 

7.  current_time  = datetime.now() 

8.  print ("当前时间： ", current_time) 

9. 202 4 年全国大学生信息安全竞赛报告 

第22 页 共 64 页

10.  names  = [] 

11.  publishs  = [] 

12.  times  = [] 

13.  current_times  = [] 

14.  # 指定要下载源代码的  npm  软件包名称和下载位置 

15.  download_path  = 'C:/Users/97091/Desktop/getgithub/npm_download' 

16. 

17.  p = sync_playwright().start() 

18.  browser  = p.chromium.launch_persistent_context( 

19.  # 指定本机用户缓存地址 

20.  user_data_dir=f "C :/Users/97091/Desktop" ,

21.  # 接收下载事件 

22.  accept_downloads=True, 

23.  # 设置  GUI  模式 

24.  headless=False, 

25.  bypass_csp=True, 

26.  slow_mo=1000, 

27.  channel= "chrome" 

28.  )

29.  page  = browser.pages[0] 

30.  url  = "https://www.npmjs.com/" 

31.  page.goto(url) 

32.  time.sleep(3) 

33. 

34.  lis  = page.query_selector( 'ul[aria -labelledby="recently -updated -

packages -header"]' ).query_selector_all( 'li' )

35.  print (len(lis)) 

36.  for  li  in  lis: 

37.  names.append(li.query_selector( 'h3' ).inner_text()) 

38.  content  = li.query_selector( 'span[aria -

hidden="true"]' ).inner_text() 

39.  publishs.append(content.split( ' • ')[0]) 

40.  times.append(content.split( ' • ')[1]) 

41.  current_times.append(current_time) 

42.  browser.close() 

43. 

44.  # 判断是否有重复值 

45.  duplicate_indexes  = get_duplicate_indexes(df,  names,  publishs) 

46.  print (duplicate_indexes) 

47.  # 根据索引删除元素 

48.  remove_elements_by_index( names,  publishs,  times,  current_times,  indexes 

=duplicate_indexes) 

49.  print (len(names)) 

50. 202 4 年全国大学生信息安全竞赛报告    

> 第23 页共64 页

51.  download_paths  = [] 

2.  数据去重与下载： 为了确保数据的唯一性和下载的有效性，我们对获取到的数 

据进行了去重处理，并在去重后下载新数据的源代码主要步骤如下：将获取到 

的包信息与已有数据进行比对，找出重复项→删除重复项，保留新数据→使用 

'npm pack' 命令下载新数据的源代码 

3.  定时任务： 为了实现持续获取，我们设置了一个循环，每隔  24  小时运行一次任 

务。该任务会自动执行数据获取、去重、下载和保存操作，实现数据的自动化 

管理 

1.  # 设置定时任务的时间间隔（以秒为单位） 

2.  interval  = 60  * 60  * 24 

3. 

4.  while  True: 

5.  # 执行任务 

6.  task() 

7. 

8.  # 等待指定的时间间隔 

9.  time.sleep(interval) 

4.  缺陷： 实际操作后发现，这种方法的缺点很明显，即官网首页展示的最新软件 

包其实十分有限，并不是全部的最新软件包，所以此方案并不能完成我们的目 

标，故淘汰。 

第二种 是在查阅资料后采用‘ _all_docs ’端点，从 

'https://skimdb.npmjs.com/registry/_all_docs '通过网络请求获取数据库中所有 

文档的  ID  和元数据，进而通过比对旧数据库和隔段时间请求的新数据库中的文件， 

找出最新更新的软件包。 

1.  import  requests 

2.  import  sys 

3.  import  time 

4.  sys.setrecursionlimit(1000000) 

5. 

6.  f = open(f 'result_final.txt' , 'ab' )

7.  error_index  = 0

8.  def  get_latest_changes(): 

9.  global  f,error _index 202 4 年全国大学生信息安全竞赛报告 

第24 页 共 64 页

10.  print ("starting" )

11.  now_index  = 0

12.  try :

13.  response  = requests.get( 'https://skimdb.npmjs.com/registry/_all_doc 

s' , stream=True,  timeout=10) 

14.  response.raise_for_status() 

15.  for  chunk  in  response.iter_content(chunk_size=8192): 

16.  now_index  +=  1

17.  print (error_index) 

18.  print (now_index) 

19.  if  now_index  >=  error_index: 

20.  f.write(chunk) 

21. 

22.  except  Exception: 

23.  if  now_index  >=  error_index: 

24.  error_index  = now_index 

25.  print ('failed  index:'  + str(error_index)) 

26.  print ('restart...' )

27.  time.sleep(10) 

28.  get_latest_changes() 

29. 

30.  get_latest_changes() 

缺陷： 实际操作后发现，虽然对比方法一可以获取全部最新软件包，此种方法 

的缺陷是过于依赖网络稳定性，以及数据库中软件包信息文档过于庞杂，导致单次 

执行程序时间太久，所以第二种方案也不能完成我们的目标，故淘汰。 

第三种是利用 'concurrent -couch -follower '库从  Npm  注册表直接获取变更数据， 

并将其保存为  JSON  文件，然后直接用自动化脚本下载文件中的新软件包，步骤如 

下： 

1.  数据获取和存储 

我们首先使用  JavaScript  编写了一个脚本‘ new_index.js ’,该脚本利用 

‘concurrent -couch -follower '库从  npm  注册表直接获取变更数据，并将其保存为 

JSON  文件，该脚本功能如下：从  npm  注册表获取最新的变更序列→使用并行请求 

（通过配置‘ concurrency ’参数）获取变更数据→将获取到的变更数据保存到本地 

目录‘ npm_changes ’中，以便后续处理。 

1.  var  dataHandler  = function(data,  done)  {

2.  console.log(data) 202 4 年全国大学生信息安全竞赛报告    

> 第25 页共64 页

3.  //  save  data  into  file  in  JSON  format 

4.  //  var  jsonData  = JSON.parse(data); 

5.  var  jsonString  = JSON.stringify(data,  null,  4); 

6.  fs.writeFile( 'npm_changes/'  + data.seq  + '.json' , jsonString,  'utf8' , f 

> unction(writeErr) {

7.  if  (writeErr)  {

8.  console.error(writeErr); 

9.  } else  {

10.  console.log(data.id  + ' JSON  data  is  saved.' ); 

11.  }

12.  }); 

13.  }

2.  文件处理与下载 

为了高效处理并下载变更数据，我们编写了一个  Python  脚本，该脚本利用多线程和 

线程池机制，确保能同时处理和下载多个文件，主要步骤如下：初始化相关目录和 

状态文件→读取已处理文件列表，避免重复处理→定义处理  JSON  文件和下载文件的 

函数，并使用线程池并行执行这些任务→使用 'watchdog' 库监控目录中新的  JSON  文

件，并在文件创建时触发处理函数。 

3.  算法调整 

此方案可行性最佳，实现过程中我们做了以下调整和优化： 

1.  并行处理 ：通过使用 'ThreadPoo0lExecutor', 我们能够并行处理多个  JSON  文件 

和下载任务，大大提高了程序的执行效率。 

2.  状态管理 ：通过使用状态文件 'processed_files.txt', 我们避免了重复处理已 

经下载的文件，节省了资源和时间。 

3.  异常处理 ：在下载文件过程中，我们设置了最大重试次数 'MAX_RETEIES' ，以确 

保在网络不稳定的情况下，程序能够进行多次尝试，从而提高下载的成功率 .

4.  文件监控 ：使用 'watchdog' 库监控目录中的新文件，当检测到新的  JSON  文件 

时，自动触发处理和下载任务，实现了完全自动化的流程。 

通过这些选择、调整和优化，我们的工具能够更高效、更可靠地获取变更数据并下 

载相关资源，满足了研究的需求。 202 4 年全国大学生信息安全竞赛报告    

> 第26 页共64 页

# 2.4  特征提取 

为了确定感兴趣的特征，我们检查了  BKC  中提供的恶意样本。由于我们的目标 

是在多种编程语言中检测恶意代码的存在，因此我们不考虑专门为某种编程语言设 

计的特征（例如，某些  API  的使用），而是关注词汇和结构方面。因此，我们采用 

了具有普遍适用性的特征，这些特征并非特定于  JavaScript 。然后，我们基于专业知 

识提出了额外的特征。 

本研究中考虑的最终特征集描述在表  2 中。这些特征捕捉了字符串、标识符、 

文件扩展名和安装钩子的使用情况的特性。由于这些特征不依赖于特定语言，因此 

相比于需要不断维护的语言特定特征（如安全相关  API  列表），它们具有不需要持 

续维护的优势。   

> 表2-1用于恶意包分类的特征集

类型  描述  记录到的行为 

布尔型  使用安装钩子  任意代码执行 

持续型  安装脚本中的单词数量  源代码结构特征 

持续型  安装脚本的行数  源代码结构特征 

持续型  源代码文件中的单词数  源代码结构特征 

持续型  源代码文件的行数  源代码结构特征 

持续型  URL  的数量  安全敏感字符串 

持续型  IP  地址的数量  安全敏感字符串 

持续型  字符串中可疑标记的数量  安全敏感字符串 

持续型  Base64  字符串的数量  存在混淆 

持续型  所有源代码文件中字符串的香农熵的平均值、标准 

差、第三四分位数和最大值 

存在混淆 202 4 年全国大学生信息安全竞赛报告    

> 第27 页共64 页

持续型  所有源代码文件中同质和异质字符串的数量  存在混淆 

持续型  所有源代码文件中字符串的香农熵的平均值、标准 

差、第三四分位数和最大值 

存在混淆 

持续型  所有源代码文件中同质和异质标识符的数量  存在混淆 

持续型  安装脚本中字符串的香农熵的平均值、标准差、第 

三四分位数和最大值 

存在混淆 

持续型  安装脚本中标识符的香农熵的平均值、标准差、第 

三四分位数和最大值 

存在混淆 

持续型  每个源代码文件中方括号比例的平均值、标准差、 

第三四分位数和最大值 

字符串操作 

持续型  每个源代码文件中等号比例的平均值、标准差、第 

三四分位数和最大值 

字符串操作 

持续型  每个源代码文件中加号比例的平均值、标准差、第 

三四分位数和最大值 

字符串操作 

持续型  每个选定扩展名的文件数量（共  91  个）  包的结构特征 

我们利用  Pygments  词法分析器来解析和处理被分析包的源代码文件 

（.js , . py ）以及安装脚本（ package.json, setup.py ）。从这些文件中，我们提取以下 

类型的词法标记：字符串、标识符、操作符和标点符号。 

在以下内容中，我们描述并解释不同特征的选择动机。 

1.  使用安装钩子。攻击者通常使用安装脚本通过安装钩子触发执行。因此，我 

们通过一个布尔特征来检测  setup.py  文件（对于  Python ）和  package.json  文

件（对于  JavaScript ）中的  install 、post -install 、pre -install  标记的存在。 

2.  代码混淆。恶意字符串通常具有混淆的特性。为了检测字符串和标识符中的 

混淆和编码（例如  base64 ），我们利用香农熵，结合广义语言（ GL ）的概 202 4 年全国大学生信息安全竞赛报告 

第28 页 共 64 页

念。广义语言在错误检测的背景下使用，通过使用预定义的字母表对数据进 

行编码，将特定值抽象为模式。 

在我们的案例中，给定一个字符串或标识符（即变量、函数和类名）作为输 

入，我们使用以下映射将每个字符  x 进行转换： 

其中， GL 4 表示使用四个符号字母表的  GL 。例如，字符串  YmFzaA== （bash  的

base64  编码）变成  ULULLUSS ，而非编码字符串如  while  则变成  LLLLL 。一旦使用 

GL 4 转换了字符串或标识符，我们分别在源代码文件和安装脚本中计算这些字符串的 

香农熵的均值、标准差、第三四分位数和最大值。同时，对于字符串和标识符，我 

们统计了同质（即在 𝐺𝐿 4 编码后所有字符都相同）和异质（即在  GL 4 编码后至少有 

一个字符不同）的数量。 

1.  # 应用泛化语言 

2.  generalization_str=[] 

3.  generalization_id=[] 

4.  # 标识符 

5.  for  h in  range( 0,len (identifiers)): 

6.  gen=alphabetic_id(identifiers[h]) 

7.  generalization_id.append(gen) 

8.  obf_sc=utilities_functions.obfuscation(generalization_id,symbols=[ 'u' ,'d' ,'

l' ,'s' ]) 

9.  # 字符串 

10.  url_sc= 0

11.  for  k in  range( 0,len(string)): 

12.  try :

13.  url_sc+=len(extractor.find_urls(string[k])) 

14.  except :

15.  url_sc  +=  len(utilities_functions.contains_URL(string[k])) 

16. 

17.  gen=alphabetic_string(string[k]) 

18.  generalization_str.append (gen) 202 4 年全国大学生信息安全竞赛报告    

> 第29 页共64 页

19.  obf_sc_str=utilities_functions.obfuscation(generalization_str,symbols=[ 'u' ,

> 'd' ,'l' ,'s' ])

敏感字符串：恶意代码通常会引入具有某些特性的字符串（如  URL 、shell  命

令）。为了检测安全相关字符串的存在，我们从  offensive security cheatsheets （如反 

向 shell 、敏感文件路径）中构建了一个关键词字典。这些关键词既包括明文也包括 

不同编码形式（如  base64 、base32 、rot -13 、URL  编码）。相应的特征是命中该字典 

的次数。 

源代码文件和字符串操作的结构特征：通过统计代码中的单词数量和代码行数 

来捕捉代码的规模。对于常用于字符串操作的符号（如加号、等号和方括号），计 

算其在文件中的比例，并报告这些符号在所有分析包中文件的均值、标准差、第三 

四分位数和最大值。 

包的结构特征：由于恶意包可能会从外部资源执行恶意软件（如二进制文件、 

shell  脚本），我们根据  BKC  中出现的恶意包构建了一个包含  91  个常用文件扩展名 

的自定义列表，并报告这些扩展名在分析包中包含的文件数量。 

为了支持上述特征的选择，我们检查了它们的统计分布，特别是比较了从良性 

包和恶意包中提取的特征分布。这使我们能够初步评估所提出的特征是否能够区分 

这两类包。通过比较良性和恶意包中的分布，我们观察到大多数特征在这两类包中 

有显著差异。即使在分布相似的情况下（如源代码文件中的  IP  地址数量），我们仍 

能检测到至少一个统计度量（如均值、中位数、最小值）在恶意包和良性包之间存 

在差异。 

# 2.5  模型训练和评估 

在模型训练和评估阶段，采用分层抽样来确保良性和恶意样本之间的  90 -10  比

例保持不变。具体操作包括： 

数据集划分：将数据集划分为单语言数据集（ JavaScript  和 Python  各一个）和跨 

语言数据集（包含  JavaScript  和 Python  的包）。 

训练算法选择：选择决策树（ DT ）、随机森林（ RF ）和极限梯度提升 

（XGBoost ）三种算法，每种算法分别在两个单语言数据集和跨语言数据集上进行 202 4 年全国大学生信息安全竞赛报告    

> 第30 页共64 页

训练，总共生成  9 个分类器。 

评估指标： 

准确率（ Accuracy ）： 

其中， 𝑇𝑃 为真阳性， 𝑇𝑁 为真阴性， 𝐹𝑃 为假阳性， 𝐹𝑁 为假阴性。 

精确率（ Precision ）： 

召回率（ Recall ）： 

F1 -score ：

超参数优化：使用贝叶斯优化器（ BO ）结合  5 折交叉验证来微调这些算法的超 

参数。优化的超参数包括： 

决策树（ DT ）：最大深度、最大特征数、分裂标准（信息增益、基尼指数、对 

数损失）、叶子节点中的最小观测数和分裂内部节点所需的最小样本数。 

随机森林（ RF ）：除了  DT  的超参数外，还包括估计器数量（决策树的数量）和 

训练每棵树的最大样本数。 

XGBoost ：树的最大深度、估计器数量、构建每棵树的特征子样本比例、学习 

率、最小分裂损失和子节点中所需的最小海森矩阵和。 202 4 年全国大学生信息安全竞赛报告    

> 第31 页共64 页

# 2.6  交叉验证 

为了评估模型的性能，采用  5 折交叉验证，并重复十次。这种方法允许我们评估 

模型的稳定性和准确性，并报告相应的评分指标（如精度、召回率、 F1  分数和准确 

率）。具体步骤如下： 

2. 分层抽样：在每次交叉验证的分割中，确保良性和恶意样本之间的  90 -10  比例 

保持不变。 

2. 训练和验证：分别在两个单语言 数据集和跨语言数据集上训练每个学习算法。 

每次交叉验证后，计算模型在正类（即恶意包）上的精度、召回率、 F1  分数和准 

确率。 

3. 重复实验：进行  5 折交叉验证，并重复十次，以获得稳定的性能评估。 

交叉验证是一种评估模型性能的技术，通过将数据集分为多个子集，逐次用一 

个子集进行验证，其他子集用于训练，从而评估模型的稳定性和泛化能力。其基本 

公式为： 

其中， Accuracy 𝑖 为第 𝑖 次验证的准确率， 𝑘 为折数。 

通过这些步骤，最终生成并评估了  9 个分类器，并确定了表现最好的模型。在单 

语言和跨语言场景中， XGBoost  模型在  JavaScrip t 和 Python  包的分类中表现最佳。 

# 2.7  大语言模型复筛 

为了进一步提高模型在检测恶意软件包方面的精度，我们精心设计了一系列标准 

化的提示词，旨在引导三款先进的大语言模型（ LLM ）—— ChatGPT 、Kimi  和文心一 

言代替人工审查以实现最有效的检测 系统 。

在设计提示词时，我们考虑了以下要素： 

1.  明确指出模型的任务是区分恶意和良性软件包。 

2.  鼓励模型在处理每个样本时，考虑所有可能的特征和模式，以做出最准确的预 202 4 年全国大学生信息安全竞赛报告    

> 第32 页共64 页

测。 

3.  要求模型在做出预测时提供一定的解释，这有助于我们了解其决策过程，从而 

进一步分析结果。 

4.  规范模型输出的格式 

为了确保我们的评估具有普遍性，我们需要从  BKC  恶意软件库中精心挑选若干 

个已被确认为恶意的软件包，这些样本覆盖了不同的恶意软件类型，以代表潜在的多 

样恶意包。同时，我们也要选取相同数量的良性软件包作为对照。 

随后我们将使用提示词对三个大语言模型进行评估， 预测验证集中的每个软件包， 

并计算每个模型的准确率，召回率，精确度和  F1  值。然后通过综合比较，我们最终 

将确定哪一个模型在恶意包复筛任务中表现最为出色， 最适合作为我们恶意包复筛的 

解决方案。 202 4 年全国大学生信息安全竞赛报告    

> 第33 页共64 页

# 第三章 作品测试与分析 

# 3.1  测试方案 

为训练和测试模型对于恶意包检测的效率和准确性，总体上需要进行本地存储 

库建立、特征提取模型训练和模型测试四个步骤。 

首先，本测试需要建立一个恶意包和良性包混合的数据集，另外下载最新版本 

的Npm 包和 PyPI 包，分别保存在本地存储库。前者 (标注数据集 )用于模型的训练与测 

试，后者 (未标注的数据集 )用于评估模型在真实环境中的效果。 

随后对数据进行预处理和特征提取，并将恶意包和良性包混合数据集分为两个 

单语言数据集和跨语言数据集。 

然后我们将尝试使用三种常见的学习算法决策树（ DT ）、随机森林（ RF ）和梯 

度提升树（ XGBoost ），在两种类型的数据集上 分别 进行训练。我们将评估这些算法 

在不同数据集上的性能，并选择表现最佳的模型用于后续的测试阶段。 

接着我们将比较三款大语言模型鉴别恶意包和良性包的能力，为后续代替人工筛 

查实现自动化检测选择最佳方案。 

最后我们将使用最新的 Npm 包和 PyPI 包测试最优的模型，并通过手工分析和大语 

言模型判断检测出的恶意包是否为“真阳性”，评估本作品在真实环境下的检测效 

果。       

> 图3-1测试流程 202 4年全国大学生信息安全竞赛报告
> 第34 页共64 页

# 3.2  测试设备 

3.2.1  开发环境 

在基于语言无关特征和 LLM 融合的开源组件投毒检测中 ，相关的重要环境或用 

到的工具如下表 3-1所示：   

> 表3-1系统开发环境

操作系统  Windows 11 

cpu 型号  2 GHz Quad -Core Intel Core i5 

RAM  16 GB 3733 MHz LPDDR4X 

基本开发环境  Python3. 11.1 

基本工具 

Pycharm  用于编写测试模型 

pytorch  运行  python  工具 

NVIDIA GTX TITANXp 

GPU(128G) 

训练模型 

anaconda  python  环境管理工具 

screen  离线训练工具 

3.2.2  环境配置 

在进行数据处理和模型使用时需要设置环境 。

在进行数据处理时 ,需要配置 python3.7+ 版本的开发环境，并安装符合下表本要 

求的 python 库   

> 表3-2python 库版本要求

Pytorch>=1.7.0 

Pandas>=2.2.1 

Pygments>=2.17.2 202 4 年全国大学生信息安全竞赛报告    

> 第35 页共64 页

Scikit -learn>=1.2.2 

Bayesian -optimization>=1.4.3 

Joblib>=1.4.2 

Numpy>=1.26.4 

Playwright>=1.44.0 

Xgboost>=2.0.3 

Openpyxl>=3.1.2 

# 3.3  数据集处理 

3.3.1  建立本地存储库 

1）本作品需要 建立一个 带有良性 包和恶意包的数据集。鉴于在真实的软件包存 

储库中，良性软件包的数量明显超过恶意软件包，我们创建一个不平衡的数据集来 

反映这一现实 ，其中 良性 样本 和恶意样本之间的比例 大约为 9:1 。其中的恶意样本， 

我们使用 BKC( Backstabbers -Knife -Collection -master )，其中 包含 2071 个JavaScript 包， 

273 个Python 包。良性包收集自常见的软件包存储库。 

2）另外我们需要爬取最新的 Npm 包和 Py PI 包用作模型测试。 

这里我们选择了 Playwright  作为爬虫工具。 使用  Playwright  的优势 首先 在于 

Playwright  支持多种主流浏览器，包括  Chromium 、Firefox  和 WebKit ，因此我们 

可以在不同的浏览器环境下进行测试和爬取，确保爬虫的兼容性。其次， Playwright 

提供了丰富的  API ，支持模拟用户行为、点击、填写表单等操作，使得爬虫可以更 

灵活地提取和操作网页数据。此外， Playwright  的性能优越，可以在多个浏览器上 

并行执行操作，加速网页加载和数据提取的过程。同时， Playwright  的 API  设计简 

洁明了，易于学习和使用，且集成了自动等待机制，减少了编写等待代码的需求， 202 4 年全国大学生信息安全竞赛报告    

> 第36 页共64 页

降低了维护成本。最重要的是， Playwright 能与真实浏览器进行交互， 从而我们 可以 

更准确地模拟用户行为，提高了爬取数据的可靠性。 

为了方便留够时间登录 Npm 官网的账号，第一次使用需要先将 oper.py 文件第 

68 行的延时函数由 3改为 300 。 

> 图3-3

然后修改文件路径。这里有三处路径需要修改，分别为 result_csv 、

download_path 和user_data_dir ，其中 result_csv 用于指定统计 npm 包信息的表格， 

download_path 用于 指定 npm 软件包 的下载位置 ，user_data_dir 用于指定浏览器的缓存 

地址。      

> 图3-4202 4年全国大学生信息安全竞赛报告
> 第37 页共64 页

接着运行程序并登录 Npm 官网。第一次运行要注意一个问题，浏览器在程序停 

止运行后会关闭并清除所有 cookie ，这样就无法保持登陆状态。所以需要在浏览器设 

置中取消勾选在关闭时清除 cookie 这个选项。  

> 图3-5

result.csv 要自建，注意是 UTF -8编码，分为 name 、publish 、time 、current_time 、

download 五列 。

最后，将第二步修改的延时函数修改回 3，再次启动程序即可将 npm 软件包下载 

到本地存储库中。可以在 npm_download 目录下查看到所有爬取到的 npm 包。 

3.3.2  特征提取 

1)  下面以  Npm  包为例介绍特征提取的过程， Py PI  包的特征提取与  Npm  包基本 

相同。 

2)  打 开  npm_feature_extractor.py  源 码 ， 修 改 两 处 文 件 路 径 。 第 一 处 为 

dangerous_tokens.json  的文件路径， dangerous_tokens.jso n 包含具有潜在危险性的代码 

片段。第二处为  npm_feature_extracted.csv  的文件路径， npm_feature_extracted.csv  包

含从  Npm  软件包中提取的特征数据。 

3)  接着再打开  npm_test.py  源码，将输入文件的路径修改为本地存储库的绝对路 

径。 202 4 年全国大学生信息安全竞赛报告     

> 第38 页共64 页
> 图3-6

4)  最后运行 npm_test.py 即可获得如图 3-7所示的特征数据。  

> 图3-7

5)  由于 很大一部分 软件包 具有不同名称但包含相同恶意行为。因此，有可能 

BKC 数据集中遇到多个重复 的数据包 。为了避免偏差，我们从数据集中删除重复 

项。我们将以下情况视为重复包 :( a)具有多个版本 。(b)在BKC 中标记为参与了某个特 

定的恶意活动。 (c)在某个特定方面 具有相同的 特征 值。在第一种情况下，我们只考 

虑最新的版本。对于属于同一活动或具有相同特征值的包，我们只取一个样本。 下

表显示了每个过滤步骤后剩下的包的数量。最后 ，我们得到了 102 个针对 Npm 的恶意 

包和 92 个针对 PyPI 的恶意包。   

> 表3-3应用每个过滤步骤后剩余的恶意样本数量

语言  样本总数  过滤  a 后剩余 

的样本数 

过滤  b 后剩余 

的样本数 

过滤  c 后剩余 

的样本数 

JavaScript  2071  1505  1408  102 

Python  273  225  133  92 202 4 年全国大学生信息安全竞赛报告    

> 第39 页共64 页

6)  最后 我们开始构建各种类型的数据集。这两个单语言数据集包含一种编程语 

言的包 :一个用于 JavaScript ，一个用于 Python 。跨语言数据集由两个单语言数据集的 

并集组成 。  

> 表3-4单语言和跨语言数据集的组成

类型  语言  恶意样本数量  良性样本数量 

单语言数据集  Javascript  102  918 

单语言数据集  Python  92  828 

跨语言数据集  Javascript+Python  194  1640 

# 3.4  模型训练与测试 

在本节中，我们概述了单语言和跨语言模型的训练过程，这些模型旨在对恶意 

包进行分类。首先，我们描述了我们构建的数据集，包括 JavaScript 和Python 中的良 

性和恶意包。然后，我们深入研究了用于获得模型的算法和优化。最后，我们展示 

了从包中提取的与语言无关的特征集合。 

3.4 .1  环境配置 

在Ubuntu18.04 中新建一个 screen, 其可以保证我们在于 GPU 断开连接的时候继续 

训练任务，在其中使用 pytorch 环境运行训练代码。     

> 表3-5常用 screen 命令

screen  -S[ 名称 ] # 新建一个 screen 202 4 年全国大学生信息安全竞赛报告    

> 第40 页共64 页

screen  -wipe # 查看已有 screen 

screen  -r [ 名称 ] # 进入该 screen 

Ctrl+A+D # 退出 screen 

激活  pytorch  环境：     

> 表3-6切换 python 环境

conda activate [ 环境名 ]

使用  python  运行训练代码，退出  screen  即可开始训练。 

3.4 .2  模型训练 

为了解决小数据集大小的限制， 我们选择 避免保留单独的 验证 集。相反，我们 

进行了一个 5倍交叉验证实验，重复了 10 次。这种方法使我们能够评估模型的性能并 

报告相应的得分指标。 

另外 在交叉验证的每次分割期间 ，我们采用分层抽样来确保良性和恶意样本之 

间保持 90 -10 的比例。 其中 split_training_testing  函数，用于将数据集拆分为训练集和 

测试集 。我们需要设置 stratify=y[:, 0:2] 来指定分层抽样，这里是目标变量  y 的前两 

列，即  Malicious  和 Package Repository 。这确保了训练集和测试集中这两列的比例 

与原始数据集中保持一致。      

> 图3-8202 4年全国大学生信息安全竞赛报告
> 第41 页共64 页

随后，我们将 每种学习算法 (即DT 、RF 、XGBoost) 分别在两个单语言数据集和 

跨语言数据集上进行训练。总共得到了 9个分类器。 

对于每一个模型的训练分为以下 5步： 

1)  加载并处理数据。 

2)  使用交叉验证和贝叶斯优化选择最佳超参数。 

3)  训练 最终的模型 。

4)  评估并打印性能指标。 

5)  生成 pkl 文件 保存训练好的模型，以便后续使用。   

> 表3-7模型训练中的关键函数

函数名  功能 

pd.read_csv  加载样本数据集 

evaluation_NPM_Pypi_xgb  使用 XGB 评估模型性能和最优超参数 

evaluation_random_forest  使用 RF 评估模型性能和最优超参数 

evaluation_decision_tree  使用 DT 评估模型性能和最优超参数 

XGBClassifier  训练 Xgboost 模型 

RandomForestClassifier  训练 RandomForest 模型 

DecisionTreeClassifier  训练 DecisionTree 模型 

joblib.dump  保存训练好的模型 202 4 年全国大学生信息安全竞赛报告      

> 第42 页共64 页
> 图3-8分类器运行示意图

3.4.3  大语言模型测试 

为了深入探究大语言模型在恶意包检测中的能力，我们设计了一个严格的测试 

方案。具体步骤如下： 

1）我们选取了 20 个软件包，其中包含 10 个已知的恶意包和 10 个良性包，确保数据集 

的平衡性和多样性。这些包分别来自不同的来源， 恶意包 涵盖了多种类型 （信息泄 

露、远程命令执行、数据窃取、依赖混淆攻击、隐蔽通信等） ，以便全面测试模型 

的泛化能力。 

2）本次研究选取了三款领先的大语言模型作为研究对象： ChatGPT 、Kimi 和文心一 

言。这些模型代表了当前自然语言处理技术的最前沿，具有强大的文本理解和生成 

能力。 

3）为了保证测试的公平性和结果的可比性，我们为 三个模型设计了一套统一的 

prompt ，确保模型在相同条件下进行判断和分析。 202 4 年全国大学生信息安全竞赛报告 

第43 页 共 64 页

图 3-9

4）我们将每个模型的检测结果详细记录在表格中，具体包括以下信息： 

◼ 包名 

◼ 标注 (人工标注是否具有恶意性 )

◼ 是否具有恶意性（模型的判断结果） 

◼ 恶意类型（ 信息泄露等 ）

◼ 恶意代码片段（模型识别出的具体代码） 

◼ 恶意代码所在文件 

◼ 测试所用模型（ ChatGPT 、Kimi 或文心一言） 

并利用以下代码计算每个模型的精确度，召回率，准确率和 F1 值。 

1.  from  sklearn.metrics  import  accuracy_score,  precision_score,  recall_score,  f1_score 

2. 

3.  y_true  = [1,  1,  1,  1,  1,  1,  1,  1,  1,  1,0,0,0,0,0,0,0,0,0,0]  # 真实标签 

4.  y_pred  = [1,  0,  1,  1,  1,  1,  0,  1,  1,  1,0,0,0,0,0,0,0,0,0,0]  # 预测标签 

5. 

6.  # 计算准确率 

7.  accuracy  = accuracy_score(y_true,  y_pred) 

8.  print (f 'Accuracy:  {accuracy:.2f}' )

9. 

10.  # 计算精确率 

11.  precision  = precision_score(y_true,  y_pred,  average= 'binary' )

12.  print (f 'Precision:  {precision:.2f}' )

13. 

14.  # 计算召回率 

15.  recall  = recall_score(y_true,  y_pred,  average= 'binary' )

16.  print (f 'Recall:  {recall:.2f}' )

17. 202 4 年全国大学生信息安全竞赛报告                

> 第44 页共64 页
> 18. #计算 F1 分数
> 19. f1 =f1_score(y_true, y_pred, average= 'binary' )
> 20. print (f 'F1 Score: {f1:.2f}' )

3.4 .4  真实环境测试 

为探究模型在真实环境下对恶意包的检测能力，我们的实验按照图  3-9 的顺序进 

行

图 3-10 

运行  import _joblib ,py ，注意这里的三个路径， model_path  指定已经训练好的模型 

文件， csv_path  指定从最新  Npm  软件包中提取的特征数据， output_path  用于指定预 

测结果保存的路径。本轮测试选用  3.4.2  中训练结果最好的模型作为分类器。 

图 3-11 202 4 年全国大学生信息安全竞赛报告    

> 第45 页共64 页

对于被至少一个模型分类为恶意的软件包，我们会进行严格的人工审查，以验证 

这些包是否为真阳性或假阳性。具体来说，对于  Npm  包，我们会手动检查其包含 

的.js 、.sh  和 package.json  文件；而对于  PyPI  包，我们则会检查其包含的 .py  和.sh  文

件。在手动分析过程中，我们会仔细寻找恶意行为的迹象，例如反向  shell  的实现和 

数据泄露的行为，并尝试去除任何混淆的脚本。 

在完成这些初步审查后，我们进一步利用具有类脑智能的大语言模型来模拟人类 

对代码进行审查。通过这种方式，我们验证大语言模型是否能够完全代替人类完成这 

部分的工作，从而提高恶意包检测的准确性和效率。 

# 3.5  结果与分析 

3. 5.1  模型训练结果与分析 

每种学习算法分别在两个单语言数据集和跨语言数据集上进行训练。 我们总共得 

到了  9 个分类器。 下表 报告了在对  JavaScript  和 Python  进行  5 倍交叉验证后，精度、 

召回率、 f1  分数和准确性的百分比值。      

> 表3-8JavaScript 在单语言模型 下的 5倍交叉验证实验结果

单语言模型（训练集： JavaScript  测试集： JavaScript ）

算法  精确度  召回率  F1  值 准确率 

DT  100.0 ±0.0  68.0 ±8.89  80.6 ±6.5  96.9 ±0.9 

RF  98.5 ±3.1  53.5 ±14.7  68.1 ±12.8  95.3 ±1.4 

XGB  96.5 ±4.0  75.5 ±6.9  84.4 ±4.2  97.3 ±0.6 202 4 年全国大学生信息安全竞赛报告         

> 第46 页共64 页
> 表3-9JavaScript 在跨语言模型 下的 5倍交叉验证实验结果

跨语言模型（训练集： JavaScript+Python  测试集： JavaScript ）

算法  精确度  召回率  F1  值 准确率 

DT  95.9 ±6.9  49.5 ±17.6  63.0 ±20.1  94.8 ±1.7 

RF  98.5 ±3.1  50.0 ±16.8  64.55 ±16.1  95.0 ±1.6 

XGB  97.1 ±3.8  63.5 ±10.3  76.3 ±7.9  96.2 ±1.0      

> 表3-10 Python 在单语言模型 下的 5倍交叉验证实验结果

单语言模型（训练集： Python  测试集： Python ）

算法  精确度  召回率  F1  值 准确率 

DT  81.6 ±18.3  28.9 ±14.8  39.4 ±11.2  92.0 ±0.6 

RF  79.2 ±9.4  51.7 ±14.4  61.0 ±9.9  93.8 ±1.0 

XGB  74.4 ±13.0  63.9 ±13.7  68.0 ±11.6  94.2 ±2.0       

> 表3-11 Python 在跨语言模型 下的 5倍交叉验证实验结果
> 跨语言模型（训练集： JavaScript+Python 测试集： Python ）

算法  精确度  召回率  F1  值 准确率 

DT  97.2 ±8.3  16.7 ±9.6  27.4 ±13.8  91.6 ±1.0 

RF  92.5 ±16.9  15.6 ±8.6  25.9 ±12.9  91.6 ±0.9 

XGB  87.1 ±11.1  55.6 ±13.4  66.9 ±11.1  94.8 ±1.5 202 4 年全国大学生信息安全竞赛报告    

> 第47 页共64 页

在 JavaScript  的单语言检测场景中 （即训练集和测试集均由  JavaScript  样本组成） ，

使用决策树（ DT ）算法训练的模型提供了最高的精度，达到了  100% 。然而，该模型 

在召回率方面表现不佳，仅为  68.0% ，这表明其容易出现大量假阴性，影响了整体的 

检测效果。相比之下，使用  XGBoost  算法训练的模型尽管精度略低，但在召回率方面 

表现更佳，达到了  75.5% 。综合考虑， XGBoost  模型在精度和召回率之间实现了最佳 

平衡，其  F1  得分为  84.4% ，在实际应用中表现出更好的稳定性和可靠性。 

在 Javascript  的跨语言检测场景中（即训练集由  JavaScript  和 Python  样本组成， 

测试集仅由  JavaScript  样本组成），随机森林（ RF ）算法提供了最高的精度。然而， 

XGBoost  模型在这种情况下也展示了最优的折衷效果，综合性能最佳。 准确率超过 

Malicious Package Detection using Metadata Information [10] 一文中 提出的  MeMPtec  表

现水平相当 

在 Python  的单语言检测场景中（即训练集和测试集均由  Python  样本组成），使 

用 DT  算法训练的模型尽管精度最高，但其召回率过低，实际效用有限。 XGBoost  算

法在这一场景下再次表现出色， 其精度为  74.4% ，召回率为  63.9% ，F1  得分为  68.0% 。

这表明  XGBoost  模型在  Python  包的检测中提供了更好的实际效用和可靠性。 

在 Python  的跨语言检测场景中（即训练集由  JavaScript  和 Python  样本组成，测 

试集仅由  Python  样本组成）， DT  算法尽管提供了最高的精度，但由于召回率过低， 

实用性受到限制。相较之下， XGBoost  模型在精度和召回率之间实现了更好的平衡， 

表现优于其他模型。 

通过对  XGBoost  模型在单语言和跨语言检测场景中的性能进行评估，可以得出 

以下结论： 

1）在 JavaScript  包的分类中，单语言模型的性能优于跨语言模型。 

2）在 Python  包的分类中，基于  XGBoost  的跨语言模型的性能略优于单语言模 

型。 

总体而言， XGBoost  模型在  JavaScript  和 Python  包的单语言和跨语言检测场景中 

均展示了在精度和召回率之间最有利的平衡， 表明其在实际恶意包检测中的应用潜力 

和有效性。 

3.5.2  大语言模型测试结果与分析 

表 3-12  是关于三款大 语言模型 对标记恶意包和良性包 进行分类的结果 202 4 年全国大学生信息安全竞赛报告     

> 第48 页共64 页
> 表3-12

模型  精确度  召回率  F1  值 准确率 

Chatgpt  1.00  1.00  1.00  1.00 

Kimi  1.00  0.90  0.95  0.95 

文心一言  1.00  0.80  0.89  0.90 

根据测试结果， 我们可以发现三款模型的精确度 （Precision ）、召回率 （Recall ）、

F1  值和准确率（ Accuracy ）都在很高的水平上，这表明它们在 区分 恶意包 和良性包时 

都取得了很好的 效果 。

然而我们也能够看到三款模型之间在召回率和  F1  值方面存在差异。具体来说： 

Chatgpt  在所有指标上都表现出了完美的性能，精确度、召回率、 F1  值和准确率 

均达到了  1.00 。这意味着  Chatgpt  模型在检测恶意包和良性包时没有漏报（ FN）或误 

报（ FP），并且在所有测试样本上都做出了正确的分类。 

对于  Kimi ，虽然 精确度也是  1.00 ，但召回率稍低于  Chatgpt  模型，为  0.90 。这意 

味着  Kimi  模型在检测恶意包时相比  Chatgpt  模型稍有遗漏，可能会漏掉一些恶意包。 

这导致了  F1  值稍低于  1.00 ，为  0.95 。

文心一言的召回率和  F1  值相比于前两个模型都有所下降，召回率为  0.80 ，F1  值

为 0.89 。这 说明文心一言模型在检测恶意包时漏报的情况更多，因此其召回率和  F1 

值都比前两个模型低。 

通过进一步分析发现， Kimi  和文心一言 在识别那些采用了混淆技术的恶意代码 

时可能会 发生错误。例如恶意包  xterm -addon -unicode -graphemes -6.0.5  使用了大量的 

Unicode  转义字符  (\uXXXX)  和混淆字符串 ，这种 行为 常用于隐藏恶意行为并逃避检 

测；zero -falhas -vilao -1.0.0  代码中使用了 _0x1d58  函数和混淆字符串数组 _0x3c01d0 ，

这些字符串经过混淆处理，使得代码逻辑不容易被分析。 

因此， 通过综合考虑选择  chatgpt  代替人工进行恶意包最后一步的审查最为合适。 

Kimi  模型和文心一言模型则可能受到了训练数据的限制或模型设计的局限，导致其 202 4 年全国大学生信息安全竞赛报告    

> 第49 页共64 页

在恶意包检测方面的性能稍逊于  Chatgpt  模型。 

3. 5.3  真实环境测试结果与分析 

下表 报告了单语言和跨语言模型 对真实环境下的软件包 进行分类的结果。 

表 3-13  单语言和跨语言模型对 最新  Npm  包进行分类的 结果 

Npm(Javascript) 

模型  良性  假阳性  真阳性  准确度 

单语言模型  10428  1229  38  3.1% 

跨语言模型  10519  1083  37  3.4% 

表 3-14  单语言和跨语言模型对 最新  PyPI  包进行分类的 结果 

PyPI(Python) 

模型  良性  假阳性  真阳性  准确度 

单语言模型  19097  485  15  3.1% 

跨语言模型  19196  385  17  4.4% 

图 3-12 npm  单语言和跨语言模型分类的 假阳性 恶意样本结果对比 202 4 年全国大学生信息安全竞赛报告    

> 第50 页共64 页

图 3-13PyPI  单语言和跨语言模型分类的 假阳性 恶意样本结果对比 

图 3-14 npm  单语言和跨语言模型分类的 真阳性 恶意样本结果对比 

图 3-15 PyPI  单语言和跨语言模型分类的 真阳性 恶意样本结果对比 

我们在  10  天内 利用大模型辅助人工 审查了  1530  个 Npm  包和 631  个 PyPI  包。

对于  Npm ，单语言模型与跨语言模型相比有  419  个独特的误报 (参见图  3-11 )。跨 

语言模型发现的唯一假阳性数为  275  个。就真阳性而言，两种模型都正确地将相同的 

37  个包分类为恶意包 (参见图  3-12 )。然而，单语言模型识别了一个额外的恶意包。在 

精度方面，跨语言模型与单语言模型相比， 表现 更好。 

对于  PyPI ，单语言模型比跨语言模型多分类  231  个恶意包。在这些包中， 228  个202 4 年全国大学生信息安全竞赛报告    

> 第51 页共64 页

是假阳性 (参见图  3-13 )， 3 个是跨语言模型遗漏的真阳性 (参见图  3-14 )。同样在  PyPI 

的情况下，跨语言模型比单语言模型具有更好的精度 (4.4% 比 3.1% ，参见表  3-13 )。

在 Beyond typosquatting: an in -depth look at package confusion [11] 一文中提到现有 

的恶意代码检测工具在识别恶意包方面具有一定的效果，但误报率依然较高 ，

Bandit4mal  在检测良性样本时的误报率高达  86% ，仅有  14% 的良性样本被正确识别； 

OSSGadget -backdoor  的误报率为  77% ，准确识别的良性样本比例仅为  23% 。而本课题 

的研究成果在现有数据的训练与测试中展现效果更为突出，通过使用跨语言模型，虽 

未明显提高精度，但误报率明显降低，且 真阳性的 样本 数量没有 减少太多，所以很大 

程度上减轻了人工工作量 。

在实验结束时，我们总共发现了  134  个以前未被检测到的恶意软件包，其中包括 

38  个针对  Npm  平台的软件包和  96  个针对  PyPI  平台的软件包。为了确保这些恶意软 

件包不再对用户造成威胁， 我们通过官方渠道将这些包报告给了各自平台的安全团队。 

在收到我们的报告后， Npm  和 PyPI  的安全团队立即对这些包进行了详细分类和进一 

步验证。经过他们的严格审查，共有  134  个恶意包被确认并从各自的存储库中删除。 

如今，这些恶意包已被彻底移除，不再对开发者和用户构成任何风险。 

此次实验不仅揭示了多个潜在的安全威胁， 还展示了我们检测系统的高效性和准 

确性。未来，我们将继续优化和完善我们的检测工具，力求在更早阶段发现和消除更 

多的潜在威胁，进一步保护开发者和用户的安全。 202 4 年全国大学生信息安全竞赛报告                

> 第52 页共64 页
> 表3-15 节选 2023 年9月到 2024 年3月检测出的恶意 PyPI 包

3. 5.4  模型对比分析 

我们的工作提出了一种监督学习方法，用于检测软件存储库 (即 Npm  和 PyPI) 中

的潜在恶意软件包，以对抗  OSS  供应链攻击。 这里有两个与之最接近的作品。 

1）Sejfia [4] 等人提出 的是 一种与代码复制器和简单克隆检测器相结合的监督学习 

方法，用于自动检测  Npm  中的恶意包。虽然他们也考虑了一些语言通用的特 

性(例如，迷你代码的存在，二进制文件 )，但他们主要关注的是  JavaScript  与

语言相关的方面 (例如使用特定的  api) 。

2）Ohm [6] 等人对  25,210  个模型进行了广泛的评估，以评估利用监督学习技术检 

测恶意软件包的可行性。他们特别关注  Npm  生态系统，并 且也 主要考虑与语 

言相关的特征，其次是更通用的特征。 202 4 年全国大学生信息安全竞赛报告    

> 第53 页共64 页

但由于这些模型和数据集不可用，我们无法直接进行比较。因此我们从特征方面 

和他们进行比较，结果如下表  3-16  所示。  

> 表3-16

# 3.6  自动化工具的实现 

在实际环境测试中，我们基于上述原理设计并实现了一种自动化工具，用于定期 

监控  Npm  和 PyPI  上最新更新的包信息，并下载其软件包 检测恶意性。 

首先，我们采用了并行处理技术，利用多线程或多进程同时执行多个任务，提高 

了爬取速度和效率。这样一来，我们能够更快速地获取到最新的软件包信息，并及时 

进行后续处理。其次，我们实现了严密的状态管理机制，确保了整个爬取过程的稳定 

性和可靠性。通过有效的状态管理，我们能够及时发现并处理异常情况，保证了系统 

的连续运行和数据的完整性。 

另外，我们还特别关注了异常处理机制的设计。在爬取过程中，我们经常会遇到 

各种网络异常、页面结构变化等问题，为了应对这些异常情况，我们实现了健壮的异 

常处理策略，包括重试机制、错误日志记录等，以确保系统在面对异常情况时能够及 202 4 年全国大学生信息安全竞赛报告    

> 第54 页共64 页

时恢复和处理，不影响整体的运行效率和数据质量。 

最后，我们引入了文件监控技术，实现了对下载文件的实时监控和管理。通过监 

控文件的创建、修改等事件，我们能够及时发现并处理下载过程中出现的问题，确保 

了下载的软件包文件的完整性和正确性。 

值得一提的是，我们结合了大语言模型的强大能力，实现了对爬取数据中的假阳 

性结果进行自动清除。通过利用大语言模型对爬取的数据进行智能分析和筛选，我们 

进一步提高了检测准确率，省去了繁琐的人工筛查步骤，大大提升了整个系统的效率 

和可用性。 

本作品还设计了一个网页来为用户提供恶意包检测的服务。 网页界面采用了现代 

简约的设计理念，提供了清晰、直观的操作界面，使用户能够轻松地查询和管理软件 

包的恶意信息。用户无需具备专业的技术背景，也可方便地使用系统功能，提升了系 

统的可访问性。 

网站首页提供了一个功能强大的查询框， 用户可以通过输入包名来查询特定软件 

包的恶意性。系统会根据用户输入的包名实时查询后端数据库，如果查询成功，系统 

将立即返回该软件包的相关信息，包括其是否具有恶意性以及其他详细属性。 

如果系统在数据库中未能找到匹配的结果，系统会自动启动一系列后台操作，首 

先根据包名爬取相应的软件包，然后利用先进的模型对该软件包进行恶意性识别。识 

别完成后，系统会将检测结果返回给用户，确保用户能够快速获得所需的信息。      

> 图3-16 202 4年全国大学生信息安全竞赛报告
> 第55 页共64 页

此外，网站还提供了一个便捷的文件拖拽功能，用户可以将待检测的软件包文件 

直接拖入查询框进行上传。如下图所示系统会立即对上传的软件包进行实时检测，快 

速分析其恶意性，并将结果反馈给用户。通过这种方式，用户无需手动输入包名即可 

获得软件包的恶意性检测结果，极大地提升了操作的便捷性和用户体验。  

> 图3-17

为了增强用户体验并提供更多有价值的信息，我们特别添加了一些可视化图表， 

以帮助用户更直观地理解和分析软件包的 安全性 分布和检测结果。 

下面这块 饼图清晰地显示了不同类别软件包（安全、警告、 恶意 ）的比例，使用 

户能够快速了解总体情况。      

> 图3-18 202 4年全国大学生信息安全竞赛报告
> 第56 页共64 页

我们还设计了一个雷达图， 用来 展示了从不同语言软件包中检测出的恶意包 的数

量对比 ，覆盖了一整年的数据 。

图 3-19 202 4 年全国大学生信息安全竞赛报告    

> 第57 页共64 页

# 第四章 创新性说明 

# 4.1  创新性方式进行爬包处理 

在研究的初始阶段  Npm  和 PyPI  爬包的方式成为了一个比较棘手的问题，由于 

官方渠道没有提供可以直接方便下载最新软件包的渠道，所以我们进行了很多种创 

新性尝试：从最初尝试监控首页爬取，到利用  all_docs  定时比较所有包的元数据， 

再到最后利用 'concurrent -couch -follower' 库从  Npm  和 PyPI  注册表直接获取变更数 

据，最终我们终于实现了这一目标，并将程序封装成 .exe  可执行文件，一键获取。 

利用 'concurrent -couch -follower' 库从  Npm  和 PyPI  注册表直接获取变更数据，对比其 

他方法优点显著，且极具创新性，不仅解决了网络获取  all_docs  元数据面临的网络 

稳定性以及获取速度问题，还解决了首页爬包软件包不全的问题。 

# 4.2  提出语言无关的特征 

通过结合之前的研究成果和专业知识，我们提出了一个包含  141  个语言无关特 

征的特征集合。这些特征可以在不同的编程语言环境下使用，为跨语言恶意软件检 

测提供了基础。 

从不同的方面来捕获软件包的结构和内容特征，以帮助检测其中是否存在恶意 

代码。这些特征的选取合理性体现在以下几个方面： 

基于通用性的特征选取：所选特征不是针对特定编程语言而设计的，而是具有 

通用性和普适性的。这样做的好处在于，这些特征可以适用于多种编程语言的环 

境，而不需要针对每种语言单独设计特征，从而简化了模型的维护和更新。 

结合专业知识：除了基于已有研究的特征之外，还结合了专业的领域知识，进 

一步丰富了特征集。这样的特征选取方法可以更全面地覆盖恶意代码的各个方面， 

提高了检测的准确性和全面性。 

多样化的特征类型：所选特征涵盖了字符串特征、标识符特征、文件扩展名、 

安装脚本使用情况等多个方面。这种多样化的特征类型使得模型能够从不同的角度 

去捕获恶意代码的特征，提高了检测的灵敏度和可靠性。 

统计分布分析支持：在特征选取过程中，对所选特征的统计分布进行了分析， 202 4 年全国大学生信息安全竞赛报告    

> 第58 页共64 页

比较了恶意软件包和良性软件包之间的特征分布情况。这些分析结果表明，所选特 

征能够有效地区分恶意和良性软件包，从而证明了特征选取的合理性和有效性。 

1.  评估了树形学习算法的性能：针对  JavaScript  和 Python  两种编程语言，对 

多种树形学习算法进行评估，发现基于  XGBoost  的跨语言和单语言模型在 

控制实验中表现最佳。 

2.  进行了真实世界的评估：通过对连续  10  天上传到  Npm  和 PyPI  的软件包进 

行分析，对模型进行了真实世界的评估。 

从实际数据收集和评估的角度出发，切实在实际环境中使用  mono -language  模型 

对恶意软件包进行分类。 

1.  数据收集和处理：在实验中，收集了在一段时间内上传到  Npm  和 PyPI  的软件 

包，并提取了这些软件包的特征信息。 

2.  分类模型的应用：使用训练模型收集到的软件包进行分类。 

3.  手动审核：对于被至少一个模型分类为恶意的软件包，进行了手动审核，以 

验 证真阳性和假阳性。 

4.  结果报告：报告了在实验中发现的恶意软件包数量，以及对应的精确度和手 

动 审核的工作量。 

# 4.3  提出多种开源软件供应链攻击进行联合研究   

> 图4-1模型训练流程图

1.  跨语言数据集训练：研究中不仅使用了单一语言的数据集（ JavaScript  或202 4 年全国大学生信息安全竞赛报告    

> 第59 页共64 页

Python ），还通过将  JavaScript  和 Python  数据集结合训练模型。这种跨语言 

的训练方法提高了模型的泛化能力，能够更有效地检测不同语言中的恶意代 

码。 

2.  多种分类算法比较：研究评估了多种分类算法（决策树、随机森林、 

XGBoost ）的性能，并针对不同数据集（单语言 和跨语言）进行了详细分 

析。通过比较不同算法的精度、召回率、 F1 -score  和准确率，确定了 

XGBoost  在各个场景中最优的平衡性能。 

3.  增强的小数据集处理方法：为了应对小数据集带来的局限性，研究采用了  5

折交叉验证并重复十次的实验方法。这种方法不仅保证了评估的稳定性，还 

利用分层抽样技术保持了数据集中良性和恶性样本的比例（ 90 -10 ），从而 

提供了更可靠的性能评估。 

4.  详细的性能指标报告：通过在正类（恶意包）上计算精度、召回率、 F1 -

score  和准确率，研究提供了详尽的模型性能指标。这些指标不仅展示了模 

型的检测能力，还揭示了不同算法在实际应用中的优劣，为选择最优算法提 

供了依据。 

# 4.4  引入大语言模型 

通过实验，选择  chatgpt  代替人工进行恶意包最后一步的审查。引入大语言模型 

（LLM ）进行恶意代码检测是一个具有创新性的重要进展 

1.  提高 检测准确性 

大语言模型利用其强大的自然语言处理能力， 能够更准确地理解代码上下文和 

复杂逻辑，从而显著提高恶意代码检测的准确性。通过大模型的深度学习机制， 

能够捕捉和分析代码中的微妙特征和行为模式，提高对恶意代码的识别能力。 

2.  跨语言检测 

大语言模型具备跨语言的适应性， 能够在不同编程语言环境下有效工作。 通过 

使用语言无关的特征和跨语言数据集进行训练， LLM  可以捕捉不同语言中恶意代 

码的共性，实现跨语言的恶意代码检测，扩大了检测范围和应用场景。 

3.  自动化与效率提升 202 4 年全国大学生信息安全竞赛报告    

> 第60 页共64 页

引入大语言模型可以实现恶意代码检测过程的高度自动化。 LLM  可以自动分 

析和处理大量的开源软件包，减少人工干预，提高检测效率。这种自动化能力尤 

其适用于应对海量软件包的实时监控和分析，提升了响应速度和处理能力。 

4.  结合上下文理解 

大语言模型能够结合代码的上下文信息进行分析， 比传统的基于特征的检测方 

法更具优势。 LLM  能够理解代码的整体结构和逻辑关系，从而更有效地识别经过 

混淆和隐藏的恶意代码，减少误报和漏报的情况。 

5.  适应性和扩展性 

通过引入大语言模型，可以不断适应新的攻击技术和恶意代码样本。 LLM  具

备持续学习的能力，可以根据最新的威胁情报和样本进行训练和更新，保持其检 

测能力的前沿。同时， LLM  的模型架构具有良好的扩展性，可以方便地扩展到其 

他编程语言和开发环境，进一步增强恶意代码检测的广度和深度。 

引入大语言模型在恶意代码检测中的应用，利用其强大的自然语言处理能力、跨 

语言适应性和自动化处理能力， 为恶意代码的准确识别和高效检测提供了创新性的解 

决方案。这不仅提高了检测的准确性和效率，还为开源软件供应链的安全提供了重要 

保障，具有广泛的应用前景和发展潜力。 202 4 年全国大学生信息安全竞赛报告    

> 第61 页共64 页

# 第五章 总结 

当前的软件生产方式从大型公司到独立开发者， 普遍依赖于大量消费开源软件包。 

为了简化下游用户对开源软件 （OSS ）的使用， 特定生态系统的包仓库和包管理器 （例 

如 PyPI 、Npm ）被创建，以促进软件模块化并提高开发效率。然而，这些机制也被恶 

意用户利用，成为传播恶意软件的渠道。开源软件供应链的攻击面广泛，恶意用户通 

过发布包含恶意代码的软件包进行攻击， 这些事件凸显了维护开源软件供应链安全的 

重要性。 

为应对这一挑战，本研究提出了多项创新点。首先，我们采用了一种创新性的方 

法进行软件包爬取和处理，确保数据的多样性和覆盖率，从而提升模型的泛化能力和 

检测效果。其次，通过结合已有研究成果和 专业 知识，提出了一个包含  141  个语言无 

关特征的特征集合，这些特征可在不同编程语言环境下使用，为跨语言恶意软件检测 

提供了基础。 特征选取基于通用性、 结合 专业 知识、 多样化特征类型 （如字符串特征、 

标识符特征、文件扩展名、安装脚本使用情况）以及统计分布分析，确保特征能够有 

效区分恶意和良性软件包，提高检测的准确性和全面性。 

研究还采用了多种开源软件供应链攻击的联合研究方法。通过将  JavaScript  和

Python  数据集结合训练模型，提升了模型的泛化能力，更有效地检测不同语言中的恶 

意代码。 我们评估了多种分类算法 （决策树、 随机森林、 XGBoost ）的性能， 发现  XGBoost 

在单语言和跨语言模型中表现最佳。此外，为了应对小数据集带来的局限性，研究采 

用了  5 折交叉验证并重复十次的实验方法， 利用分层抽样技术保持数据集良性和恶性 

样本的比例（ 90 -10 ），确保评估的稳定性和可靠性。通过精度、召回率、 F1 -score  和

准确率等指标， 详细展示了模型的检测能力， 并揭示了不同算法在实际应用中的优劣。 

此外，本研究引入大语言模型（ LLM ）进行恶意代码定位与进一步提高分类检测 

准确率。通过大语言模型的强大自然语言处理能力和上下文理解能力，结合先前筛选 

的特征集合， 大大增强了对复杂恶意代码的识别能力。 通过对不同大模型的对比分析， 

为网络安全工作者提供了有价值的参考， 帮助他们选择最适合的模型以提高恶意代码 

检测的准确性和效率。 

本研究不仅在技术方法上进行了创新，还展望了未来的应用前景。跨语言方法 在202 4 年全国大学生信息安全竞赛报告    

> 第62 页共64 页

检测  Npm  和 PyPI  中的恶意软件包方面的成功表明，这一方法可以扩展到其他语言环 

境（如  Ruby  和 PHP ），从而提升恶意软件检测的范围和效果，保护更广泛的软件生 

态系统。 研究发现  XGBoost  在分类恶意和良性软件包时表现更佳， 未来可以继续探索 

和优化其他机器学习算法，进一步提高检测的准确性和效率。 

此外， 当前研究采用了简单但有效的特征集， 未来工作可以通过添加更多特征 （如 

代码行为和结构相关特征）进一步细化模型，提高检测的精度和鲁棒性。未来还计划 

将机器学习分类器与对同一作者上传的软件包的自动分析相结合， 通过分析与已确认 

恶意软件包相同作者相关联的软件包，更有效地发现并处理恶意软件，提高整个生态 

系统的安全性。 

通过创新的数据处理方式、提出语言无关特征、评估多种分类算法、进行真实世 

界的评估及跨语言数据集训练，并引入大语言模型定位恶意代码，本研究显著提升了 

恶意软件包检测模型的准确性和可靠性， 为开源软件供应链安全提供了重要支持和保 

障。未来在跨语言检测、机器学习算法优化、特征集扩展和结合作者分析等方向具有 

广阔的发展潜力，继续深入研究将进一步提升恶意软件检测能力，保障开源软件生态 

系统的安全。 202 4 年全国大学生信息安全竞赛报告    

> 第63 页共64 页


