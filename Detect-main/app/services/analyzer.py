import requests
import json
import re
from config import Config
from app.utils.helpers import get_setting
from typing import Dict, Any

class DeepSeekAnalyzer:
    def __init__(self, api_key=None):
        # ä¼˜å…ˆä½¿ç”¨config.pyä¸­çš„API Key
        self.api_key = api_key or Config.DEEPSEEK_API_KEY
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        print(f"[DEBUG] DeepSeekAnalyzer initialization - API Key: {self.api_key}")
        print(f"[DEBUG] DeepSeekAnalyzer initialization - API URL: {self.api_url}")
    
    def analyze_package(self, filename, features, xgboost_result):
        """åˆ†æè½¯ä»¶åŒ…çš„å®‰å…¨æ€§"""
        try:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {self.api_key}'
            }
            
            prompt = self._build_analysis_prompt(filename, features, xgboost_result)
            
            data = {
                'model': 'deepseek-chat',
                'messages': [
                    {'role': 'system', 'content': 'You are a professional open source component security analysis expert.'},
                    {'role': 'user', 'content': prompt}
                ],
                'temperature': 0.3,
                'max_tokens': 2000
            }
            
            print(f"[DEBUG] about to send API request to: {self.api_url}")
            print(f"[DEBUG] headers: {headers}")
            print(f"[DEBUG] request data: {data}")
            
            response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
            
            print(f"[DEBUG] API response status code: {response.status_code}")
            print(f"[DEBUG] API response headers: {dict(response.headers)}")
            print(f"[DEBUG] API response content: {response.text}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"[DEBUG] API returned JSON: {result}")
                
                if 'choices' in result and len(result['choices']) > 0:
                    analysis = result['choices'][0]['message']['content']
                    print(f"[DEBUG] extracted analysis content: {analysis}")
                    
                    parsed_result = self._parse_analysis(analysis, xgboost_result)
                    print(f"[DEBUG] parsed result: {parsed_result}")
                    return parsed_result
                else:
                    print(f"[DEBUG] API returned format exception: {result}")
                    return self._fallback_analysis(xgboost_result)
            else:
                print(f"[DEBUG] DeepSeek API error: {response.status_code} - {response.text}")
                return self._fallback_analysis(xgboost_result)
                
        except requests.exceptions.Timeout:
            print("[DEBUG] API request timeout")
            return self._fallback_analysis(xgboost_result)
        except requests.exceptions.RequestException as e:
            print(f"[DEBUG] API request exception: {e}")
            return self._fallback_analysis(xgboost_result)
        except Exception as e:
            print(f"[DEBUG] DeepSeek analysis exception: {e}")
            import traceback
            print(f"[DEBUG] exception stack: {traceback.format_exc()}")
            return self._fallback_analysis(xgboost_result)
    
    def _convert_markdown_to_friendly_text(self, markdown_text):
        """å°†markdownæ ¼å¼çš„åˆ†æç»“æœè½¬æ¢ä¸ºå‹å¥½çš„ä¸­æ–‡æ˜¾ç¤ºæ ¼å¼"""
        if not markdown_text:
            return "æš‚æ— åˆ†æç»“æœ"
        
        # ç§»é™¤markdownåˆ†éš”ç¬¦
        text = re.sub(r'^---+$', '', markdown_text, flags=re.MULTILINE)
        
        # è½¬æ¢æ ‡é¢˜
        text = re.sub(r'### ğŸ›¡ï¸ (.+)', r'ğŸ”’ \1', text)
        text = re.sub(r'#### (\d+ï¸âƒ£) (.+)', r'ğŸ“‹ \2', text)
        
        # è½¬æ¢è¡¨æ ¼ä¸ºæ›´å‹å¥½çš„æ ¼å¼
        def convert_table(match):
            table_content = match.group(0)
            # ç§»é™¤è¡¨æ ¼æ ‡è®°
            table_content = re.sub(r'\|.*\|.*\|.*\|', '', table_content)
            table_content = re.sub(r'\|-+\|', '', table_content)
            # æå–è¡¨æ ¼å†…å®¹å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
            lines = [line.strip() for line in table_content.split('\n') if line.strip() and '|' in line]
            result = []
            for line in lines:
                cells = [cell.strip() for cell in line.split('|') if cell.strip()]
                if len(cells) >= 3:
                    result.append(f"â€¢ {cells[0]}: {cells[1]} - {cells[2]}")
            return '\n'.join(result) if result else "æš‚æ— å…·ä½“ç‰¹å¾æ•°æ®"
        
        text = re.sub(r'\|.*\|.*\|.*\|[\s\S]*?\|.*\|.*\|.*\|', convert_table, text)
        
        # è½¬æ¢å…¶ä»–markdownæ ¼å¼
        text = re.sub(r'\*\*(.+?)\*\*', r'ã€\1ã€‘', text)  # ç²—ä½“
        text = re.sub(r'`(.+?)`', r'ã€Œ\1ã€', text)  # ä»£ç 
        text = re.sub(r'> (.+)', r'ğŸ’¡ \1', text)  # å¼•ç”¨
        
        # è½¬æ¢åˆ—è¡¨
        text = re.sub(r'^\s*-\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*(\d+)\.\s+(.+)$', r'\1. \2', text, flags=re.MULTILINE)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
        
        # æ·»åŠ ä¸­æ–‡è¯´æ˜
        text = text.replace('Judgment', 'åˆ¤æ–­ç»“æœ')
        text = text.replace('Confidence', 'ç½®ä¿¡åº¦')
        text = text.replace('Risk score', 'é£é™©åˆ†æ•°')
        text = text.replace('Malicious', 'æ¶æ„')
        text = text.replace('Benign', 'è‰¯æ€§')
        text = text.replace('High', 'é«˜é£é™©')
        text = text.replace('Medium', 'ä¸­é£é™©')
        text = text.replace('Low', 'ä½é£é™©')
        text = text.replace('Risk level', 'é£é™©ç­‰çº§')
        text = text.replace('Main risk points', 'ä¸»è¦é£é™©ç‚¹')
        text = text.replace('Security suggestions', 'å®‰å…¨å»ºè®®')
        text = text.replace('Suggestion', 'å»ºè®®')
        text = text.replace('Note', 'æ³¨æ„')
        text = text.replace('This report is generated automatically by AI', 'æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ')
        text = text.replace('please combine manual security review', 'è¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥')
        
        return text.strip()
    
    def _build_analysis_prompt(self, filename, features, xgboost_result):
        # æå–å…³é”®ç‰¹å¾ç”¨äºåˆ†æ
        key_features = {
            'file_size': features.get('file_size', 'N/A'),
            'Number of Words in source code': features.get('Number of Words in source code', 'N/A'),
            'Number of lines in source code': features.get('Number of lines in source code', 'N/A'),
            'Number of base64 chunks in source code': features.get('Number of base64 chunks in source code', 'N/A'),
            'Number of IP adress in source code': features.get('Number of IP adress in source code', 'N/A'),
            'Number of sospicious token in source code': features.get('Number of sospicious token in source code', 'N/A'),
            'shannon mean ID source code': features.get('shannon mean ID source code', 'N/A'),
            'shannon max ID source code': features.get('shannon max ID source code', 'N/A'),
            'plus ratio max': features.get('plus ratio max', 'N/A'),
            'eq ratio max': features.get('eq ratio max', 'N/A'),
            'bracket ratio max': features.get('bracket ratio max', 'N/A'),
        }
        # ä¿®å¤ï¼šç”Ÿæˆç‰¹å¾æ‘˜è¦
        feature_summary = '\n'.join([f'- {k}: {v}' for k, v in key_features.items()])

        prompt = f"""
è¯·ä½œä¸ºä¸“ä¸šçš„å¼€æºç»„ä»¶å®‰å…¨åˆ†æä¸“å®¶ï¼Œç»“åˆä¸‹æ–¹è¯¦ç»†ç‰¹å¾æ•°æ®ï¼Œåˆ†æè¯¥åŒ…å¯èƒ½å­˜åœ¨çš„å®‰å…¨é£é™©ã€æ¶æ„è¡Œä¸ºæˆ–å¯ç–‘ç‚¹ï¼Œå¹¶è¯´æ˜ç†ç”±ï¼š

- æ–‡ä»¶åï¼š{filename}
- ä¸»è¦ç‰¹å¾æ•°æ®ï¼ˆä»…å±•ç¤ºéƒ¨åˆ†ï¼‰ï¼š
{feature_summary}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š

### 1ï¸âƒ£ æ¶æ„ç±»å‹åˆ¤æ–­
- **ç±»å‹**ï¼šè¯·æ ¹æ®ç‰¹å¾å’Œåˆ†æï¼Œåˆ¤æ–­è¯¥åŒ…æœ€å¯èƒ½å±äºå“ªç±»æ¶æ„ç±»å‹ï¼ˆå¦‚"ä¿¡æ¯çªƒå–"ã€"è¿œç¨‹æ§åˆ¶"ã€"ä¾èµ–æ··æ·†"ã€"æŒ–çŸ¿è„šæœ¬"ã€"åé—¨æœ¨é©¬"ç­‰ï¼‰ï¼Œå¦‚æ— æ˜æ˜¾æ¶æ„å¯å†™"æ— æ˜æ˜¾æ¶æ„"
- **ç†ç”±**ï¼šè¯·ç”¨ç®€æ˜ä¸­æ–‡è¯´æ˜åˆ¤æ–­ä¾æ®ï¼Œéœ€ç»“åˆç‰¹å¾å€¼ï¼ˆå¦‚"å‘ç°å¤§é‡base64ç¼–ç ï¼Œä¸”å­˜åœ¨å¯ç–‘ç½‘ç»œè¯·æ±‚ï¼Œç–‘ä¼¼ä¿¡æ¯çªƒå–"ï¼‰

### 2ï¸âƒ£ ä¸»è¦å¯ç–‘ç‰¹å¾ï¼ˆTop 5ï¼‰
| ç‰¹å¾åç§° | æ•°å€¼ | æè¿°/é£é™©ç‚¹ |
|---|---|---|
| ç¤ºä¾‹ï¼šç†µå‡å€¼ | 0.72 | ä»£ç æ··æ·†ã€å˜é‡åå¼‚å¸¸ |
| ... | ... | ... |

### 3ï¸âƒ£ é£é™©ç­‰çº§è¯„ä¼°
- **é£é™©ç­‰çº§**ï¼šé«˜/ä¸­/ä½
- **ä¸»è¦é£é™©ç‚¹**ï¼š1. ... 2. ...

### 4ï¸âƒ£ å®‰å…¨å»ºè®®
- å»ºè®®1ï¼š...
- å»ºè®®2ï¼š...

> **æ³¨æ„**ï¼šæ‰€æœ‰å†…å®¹è¯·ç”¨ä¸­æ–‡è¾“å‡ºï¼Œç»“æ„åŒ–å±•ç¤ºï¼Œä¾¿äºäººå·¥å¤æ ¸ã€‚
"""

        # è¿½åŠ ç»“æ„åŒ–Markdownæ ¼å¼è¦æ±‚
        prompt += f'''
---
### ğŸ›¡ï¸ å¼€æºç»„ä»¶å®‰å…¨åˆ†ææŠ¥å‘Š: {filename}

#### 1ï¸âƒ£ XGBooståˆ¤æ–­ç»“æœ
- **åˆ¤æ–­ç»“æœ**ï¼š{'æ¶æ„' if xgboost_result.get('prediction', 0) == 1 else 'è‰¯æ€§'}
- **ç½®ä¿¡åº¦**ï¼š{xgboost_result.get('confidence', 0.0) * 100:.2f}%
- **é£é™©åˆ†æ•°**ï¼š{xgboost_result.get('risk_score', 0.0):.3f}

#### 2ï¸âƒ£ ä¸»è¦å¯ç–‘ç‰¹å¾ï¼ˆTop 5ï¼‰
è¯·ç”¨ä¸‹è¡¨å±•ç¤ºæœ€å¯ç–‘çš„5ä¸ªç‰¹å¾ï¼š

| ç‰¹å¾åç§° | æ•°å€¼ | æè¿°/é£é™©ç‚¹ |
|---|---|---|
| ç¤ºä¾‹ï¼šç†µå‡å€¼ | 0.72 | ä»£ç æ··æ·†ã€å˜é‡åå¼‚å¸¸ |
| ... | ... | ... |

#### 3ï¸âƒ£ é£é™©ç­‰çº§è¯„ä¼°
- **é£é™©ç­‰çº§**ï¼šé«˜/ä¸­/ä½
- **ä¸»è¦é£é™©ç‚¹**ï¼š
  1. ...
  2. ...

#### 4ï¸âƒ£ å®‰å…¨å»ºè®®
- å»ºè®®1ï¼š...
- å»ºè®®2ï¼š...

#### 5ï¸âƒ£ æ¶æ„åŒ…ç±»å‹åˆ¤æ–­
- ç±»å‹ï¼šè¯·æ ¹æ®ç‰¹å¾å’Œåˆ†æï¼Œåˆ¤æ–­è¯¥åŒ…æœ€å¯èƒ½å±äºå“ªç±»æ¶æ„ç±»å‹ï¼ˆå¦‚"ä¿¡æ¯çªƒå–"ã€"è¿œç¨‹æ§åˆ¶"ã€"ä¾èµ–æ··æ·†"ã€"æŒ–çŸ¿è„šæœ¬"ã€"åé—¨æœ¨é©¬"ç­‰ï¼‰ï¼Œå¦‚æ— æ˜æ˜¾æ¶æ„å¯å†™"æ— æ˜æ˜¾æ¶æ„"
- ç†ç”±ï¼šè¯·ç”¨ä¸€å¥è¯è¯´æ˜åˆ¤æ–­ä¾æ®

---

> **æ³¨æ„**ï¼šæœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œè¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥ã€‚

è¯·ä¸¥æ ¼ä½¿ç”¨Markdownåˆ†çº§æ ‡é¢˜ï¼ˆ###ã€####ï¼‰ã€è¡¨æ ¼ã€åˆ—è¡¨ã€åŠ ç²—ç­‰ç»“æ„åŒ–æ ¼å¼ï¼Œé¿å…è¾“å‡ºå¤§æ®µæ— ç»“æ„æ–‡æœ¬ã€‚æ‰€æœ‰å†…å®¹è¯·ç”¨ä¸­æ–‡è¾“å‡ºã€‚'''
        return prompt
    
    def _parse_analysis(self, analysis_text, xgboost_result=None):
        """è§£æDeepSeekçš„åˆ†æç»“æœï¼Œrisk_levelä¸XGBooståˆ†æ•°è”åŠ¨"""
        print(f"[DEBUG] start parsing analysis text: {analysis_text[:200]}...")

        # å¦‚æœå¤§æ¨¡å‹è¿”å›å†…å®¹ä¸ºç©ºæˆ–å…¨æ˜¯æ— ï¼Œè‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–å…œåº•å†…å®¹
        if not analysis_text or analysis_text.strip() == '' or all(x in analysis_text for x in ['ç±»å‹', 'æœªçŸ¥', 'æ— ', 'æš‚æ— ']):
            print("[DEBUG] å¤§æ¨¡å‹è¿”å›å†…å®¹ä¸ºç©ºæˆ–å…¨ä¸ºæ— ï¼Œè‡ªåŠ¨ç”Ÿæˆå…œåº•å†…å®¹")
            # å…œåº•å†…å®¹æ ¹æ®XGBoostç»“æœå’Œç‰¹å¾ç”Ÿæˆ
            if xgboost_result:
                pred = xgboost_result.get('prediction', 0)
                conf = xgboost_result.get('confidence', 0.0)
                risk_score = xgboost_result.get('risk_score', 0.0)
                # æ¶æ„ç±»å‹
                mal_type = 'é«˜é£é™©å¯ç–‘åŒ…' if pred == 1 else 'æ— æ˜æ˜¾æ¶æ„'
                mal_reason = 'æœºå™¨å­¦ä¹ æ¨¡å‹åˆ¤å®šä¸ºé«˜é£é™©ï¼Œå»ºè®®äººå·¥å¤æ ¸' if pred == 1 else 'æœªå‘ç°æ˜æ˜¾æ¶æ„ç‰¹å¾ï¼Œæ¨¡å‹åˆ¤å®šä¸ºå®‰å…¨'
                # å¯ç–‘ç‰¹å¾
                features = xgboost_result.get('features', {}) if 'features' in xgboost_result else {}
                suspicious = []
                if features:
                    if features.get('Number of base64 chunks in source code', 0) > 10:
                        suspicious.append('| Base64å—æ•°é‡ | {} | ä»£ç ä¸­å­˜åœ¨å¤§é‡Base64ç¼–ç  |'.format(features['Number of base64 chunks in source code']))
                    if features.get('Number of sospicious token in source code', 0) > 10:
                        suspicious.append('| å¯ç–‘tokenæ•°é‡ | {} | ä»£ç ä¸­å­˜åœ¨å¤§é‡å¯ç–‘token |'.format(features['Number of sospicious token in source code']))
                    if features.get('.py', 0) > 1000:
                        suspicious.append('| Pythonæ–‡ä»¶æ•° | {} | ä»£ç ä½“é‡å·¨å¤§ |'.format(features['.py']))
                if not suspicious:
                    suspicious.append('æš‚æ— å¯ç–‘ç‰¹å¾æ•°æ®')
                suspicious_md = '\n'.join(suspicious)
                # é£é™©ç­‰çº§
                risk_level = 'HIGH' if pred == 1 else 'SAFE'
                risk_points = 'æœºå™¨å­¦ä¹ æ¨¡å‹åˆ¤å®šä¸ºé«˜é£é™©' if pred == 1 else 'æ— '
                # å®‰å…¨å»ºè®®
                if pred == 1:
                    advice = ['- å»ºè®®äººå·¥å¤æ ¸', '- å»ºè®®åœæ­¢ä½¿ç”¨', '- å…³æ³¨å®˜æ–¹å®‰å…¨å…¬å‘Š']
                else:
                    advice = ['- å»ºè®®å®šæœŸå…³æ³¨å®‰å…¨å…¬å‘Š', '- å»ºè®®æŒç»­ç›‘æ§ç»„ä»¶å®‰å…¨']
                advice_md = '\n'.join(advice)
                analysis_text = f"""### æ¶æ„ç±»å‹åˆ¤æ–­\nç±»å‹ï¼š{mal_type}\nç†ç”±ï¼š{mal_reason}\n\n### ä¸»è¦å¯ç–‘ç‰¹å¾ï¼ˆTop 5ï¼‰\n{suspicious_md}\n\n### é£é™©ç­‰çº§è¯„ä¼°\né£é™©ç­‰çº§ï¼š{risk_level}\nä¸»è¦é£é™©ç‚¹ï¼š{risk_points}\n\n### å®‰å…¨å»ºè®®\n{advice_md}\n"""
            else:
                analysis_text = """### æ¶æ„ç±»å‹åˆ¤æ–­\nç±»å‹ï¼šæ— æ˜æ˜¾æ¶æ„\nç†ç”±ï¼šæœªå‘ç°æ˜æ˜¾æ¶æ„ç‰¹å¾ï¼Œæœºå™¨å­¦ä¹ æ¨¡å‹åˆ¤å®šä¸ºå®‰å…¨ã€‚\n\n### ä¸»è¦å¯ç–‘ç‰¹å¾ï¼ˆTop 5ï¼‰\næš‚æ— å¯ç–‘ç‰¹å¾æ•°æ®\n\n### é£é™©ç­‰çº§è¯„ä¼°\né£é™©ç­‰çº§ï¼šSAFE\nä¸»è¦é£é™©ç‚¹ï¼šæ— \n\n### å®‰å…¨å»ºè®®\n- å»ºè®®å®šæœŸå…³æ³¨å®‰å…¨å…¬å‘Š\n- å»ºè®®æŒç»­ç›‘æ§ç»„ä»¶å®‰å…¨\n"""

        # é»˜è®¤ä¸­é£é™©
        risk_level = 'medium'
        
        # å…ˆç”¨å¤§æ¨¡å‹æ–‡æœ¬å…³é”®è¯åˆ¤å®š
        if 'High risk' in analysis_text or 'High danger' in analysis_text or 'Malicious' in analysis_text:
            risk_level = 'high'
        elif 'Low risk' in analysis_text or 'Safe' in analysis_text or 'Normal' in analysis_text:
            risk_level = 'low'
        
        # å¦‚æœXGBooståˆ†æ•°å¾ˆé«˜ï¼Œå¼ºåˆ¶high
        if xgboost_result:
            risk_score = xgboost_result.get('risk_score', 0)
            confidence = xgboost_result.get('confidence', 0)
            print(f"[DEBUG] XGBoost risk score: {risk_score}, confidence: {confidence}")
            
            # åªè¦risk_scoreæˆ–confidenceå¤§äº0.6å°±high
            if risk_score >= 0.6 or confidence >= 0.8:
                risk_level = 'high'
                print(f"[DEBUG] forced to high risk based on XGBoost score")
            elif risk_score >= 0.4 or confidence >= 0.6:
                risk_level = 'medium'
            elif risk_score >= 0.2 or confidence >= 0.3:
                risk_level = 'low'
            else:
                risk_level = 'safe'
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºæ–‡æœ¬é•¿åº¦å’Œå…³é”®è¯ï¼‰
        confidence = 0.7
        if len(analysis_text) > 200:
            confidence += 0.1
        if any(word in analysis_text for word in ['Obvious', 'Determined', 'Definitely', 'Malicious', 'Dangerous']):
            confidence += 0.1
        if any(word in analysis_text for word in ['Possible', 'Perhaps', 'Suggest', 'Need further']):
            confidence -= 0.1
        
        confidence = max(0.5, min(0.95, confidence))
        
        # è½¬æ¢markdownä¸ºå‹å¥½çš„ä¸­æ–‡æ˜¾ç¤ºæ ¼å¼
        friendly_analysis = self._convert_markdown_to_friendly_text(analysis_text)
        
        # è‡ªåŠ¨æå–æ¶æ„åŒ…ç±»å‹
        mal_type = "æœªçŸ¥"
        mal_type_reason = ""
        
        # å°è¯•ä»ä¸åŒæ ¼å¼ä¸­æå–ç±»å‹å’Œç†ç”±
        type_patterns = [
            r'ç±»å‹[ï¼š: ]*([\u4e00-\u9fa5A-Za-z0-9_\-]+)',
            r'æ¶æ„ç±»å‹[ï¼š: ]*([\u4e00-\u9fa5A-Za-z0-9_\-]+)',
            r'åˆ¤å®šç±»å‹[ï¼š: ]*([\u4e00-\u9fa5A-Za-z0-9_\-]+)'
        ]
        
        reason_patterns = [
            r'ç†ç”±[ï¼š: ]*(.+?)(?=\n|$)',
            r'åˆ¤æ–­ä¾æ®[ï¼š: ]*(.+?)(?=\n|$)',
            r'åˆ†æç»“æœ[ï¼š: ]*(.+?)(?=\n|$)'
        ]
        
        # å°è¯•æ‰€æœ‰æ¨¡å¼ç›´åˆ°æ‰¾åˆ°åŒ¹é…
        for pattern in type_patterns:
            type_match = re.search(pattern, analysis_text)
            if type_match:
                mal_type = type_match.group(1).strip()
                break
                
        for pattern in reason_patterns:
            reason_match = re.search(pattern, analysis_text)
            if reason_match:
                mal_type_reason = reason_match.group(1).strip()
                break
        
        # æå–ä¸»è¦å¯ç–‘ç‰¹å¾
        top_features = []
        try:
            # å°è¯•ä»è¡¨æ ¼ä¸­æå–
            table_pattern = r'\|(.*?)\|(.*?)\|(.*?)\|'
            matches = re.findall(table_pattern, analysis_text)
            if matches:
                # è·³è¿‡è¡¨å¤´
                for match in matches[1:6]:  # åªå–å‰5ä¸ª
                    name = match[0].strip()
                    value = match[1].strip()
                    desc = match[2].strip()
                    if name and value and desc and name != "ç‰¹å¾åç§°":
                        top_features.append({
                            "name": name,
                            "value": value,
                            "desc": desc
                        })
        except Exception as e:
            print(f"[DEBUG] æå–å¯ç–‘ç‰¹å¾å¤±è´¥: {e}")
        
        # æå–å®‰å…¨å»ºè®®
        advice_list = []
        try:
            advice_section = re.search(r'å®‰å…¨å»ºè®®[ï¼š:](.*?)(?=###|$)', analysis_text, re.DOTALL)
            if advice_section:
                advice_text = advice_section.group(1)
                # æå–åˆ—è¡¨é¡¹
                advice_items = re.findall(r'[â€¢\-\*]\s*(.+?)(?=\n|$)', advice_text)
                advice_list = [item.strip() for item in advice_items if item.strip()]
        except Exception as e:
            print(f"[DEBUG] æå–å®‰å…¨å»ºè®®å¤±è´¥: {e}")
        
        # æå–é£é™©ç‚¹
        risk_points = ""
        try:
            risk_section = re.search(r'ä¸»è¦é£é™©ç‚¹[ï¼š:](.*?)(?=###|$)', analysis_text, re.DOTALL)
            if risk_section:
                risk_points = risk_section.group(1).strip()
        except Exception as e:
            print(f"[DEBUG] æå–é£é™©ç‚¹å¤±è´¥: {e}")

        result = {
            'risk_level': risk_level,
            'confidence': confidence,
            'analysis': friendly_analysis,  # ä½¿ç”¨è½¬æ¢åçš„å‹å¥½æ ¼å¼
            'raw_analysis': analysis_text,  # ä¿ç•™åŸå§‹markdownæ ¼å¼
            'type': mal_type,
            'reason': mal_type_reason,
            'top_features': top_features,
            'advice_list': advice_list,
            'risk_points': risk_points
        }
        
        print(f"[DEBUG] parsed result: {result}")
        return result
    
    def _fallback_analysis(self, xgboost_result):
        """å½“APIè°ƒç”¨å¤±è´¥æ—¶çš„åå¤‡åˆ†æ"""
        print("[DEBUG] using fallback analysis")
        
        # æ ¹æ®XGBoostç»“æœç”Ÿæˆåˆ†ææ–‡æœ¬
        if xgboost_result.get('prediction', 0) == 1:
            analysis_text = f"""ğŸ”’ å¼€æºç»„ä»¶å®‰å…¨åˆ†ææŠ¥å‘Š

ğŸ“‹ XGBooståˆ¤æ–­ç»“æœ
â€¢ åˆ¤æ–­ç»“æœï¼šæ¶æ„
â€¢ ç½®ä¿¡åº¦ï¼š{xgboost_result.get('confidence', 0.0) * 100:.2f}%
â€¢ é£é™©åˆ†æ•°ï¼š{xgboost_result.get('risk_score', 0.0):.3f}

ğŸ“‹ ä¸»è¦é£é™©ç‚¹
â€¢ æœºå™¨å­¦ä¹ æ¨¡å‹è¯†åˆ«ä¸ºé«˜é£é™©ç»„ä»¶
â€¢ å»ºè®®è¿›è¡Œè¿›ä¸€æ­¥çš„äººå·¥å®¡æŸ¥ä»¥ç¡®è®¤æ˜¯å¦å­˜åœ¨æ¶æ„ä»£ç æˆ–å®‰å…¨æ¼æ´

ğŸ“‹ å®‰å…¨å»ºè®®
â€¢ ç«‹å³åœæ­¢ä½¿ç”¨è¯¥ç»„ä»¶
â€¢ æ£€æŸ¥å·²éƒ¨ç½²çš„åº”ç”¨æ˜¯å¦å—å½±å“
â€¢ å¯»æ‰¾å®‰å…¨çš„æ›¿ä»£ç»„ä»¶
â€¢ å°†è¯¥ç»„ä»¶æŠ¥å‘Šç»™ç›¸åº”çš„åŒ…ç®¡ç†å¹³å°

ğŸ’¡ æ³¨æ„ï¼šæœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œè¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥"""
            risk_level = 'high'
        else:
            analysis_text = f"""ğŸ”’ å¼€æºç»„ä»¶å®‰å…¨åˆ†ææŠ¥å‘Š

ğŸ“‹ XGBooståˆ¤æ–­ç»“æœ
â€¢ åˆ¤æ–­ç»“æœï¼šè‰¯æ€§
â€¢ ç½®ä¿¡åº¦ï¼š{xgboost_result.get('confidence', 0.0) * 100:.2f}%
â€¢ é£é™©åˆ†æ•°ï¼š{xgboost_result.get('risk_score', 0.0):.3f}

ğŸ“‹ å®‰å…¨è¯„ä¼°
â€¢ æœºå™¨å­¦ä¹ æ¨¡å‹åˆ†ææ˜¾ç¤ºè¯¥ç»„ä»¶åŒ…ç›¸å¯¹å®‰å…¨
â€¢ æœªå‘ç°æ˜æ˜¾çš„æ¶æ„è¡Œä¸ºæˆ–å®‰å…¨æ¼æ´

ğŸ“‹ å®‰å…¨å»ºè®®
â€¢ å»ºè®®å®šæœŸæ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ä»¥ç¡®ä¿å®‰å…¨
â€¢ ä¿æŒå¯¹ç»„ä»¶åŒ…çš„æŒç»­ç›‘æ§
â€¢ å…³æ³¨å®˜æ–¹å®‰å…¨å…¬å‘Š

ğŸ’¡ æ³¨æ„ï¼šæœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œè¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥"""
            risk_level = 'low'
        
        return {
            'risk_level': risk_level,
            'confidence': xgboost_result.get('confidence', 0.5),
            'analysis': analysis_text,
            'raw_analysis': analysis_text,
            'recommendation': 'å»ºè®®ç»“åˆäººå·¥å®¡æŸ¥å’Œå®šæœŸå®‰å…¨æ›´æ–°'
        }