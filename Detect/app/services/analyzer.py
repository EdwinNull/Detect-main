import requests
import json
import re
from config.config import Config
from app.utils.helpers import get_setting
from typing import Dict, Any

class DeepSeekAnalyzer:
    def __init__(self, api_key=None):
        # ä¼˜å…ˆä½¿ç”¨config.pyä¸­çš„API Key
        self.api_key = api_key or Config.DEEPSEEK_API_KEY
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        print(f"[DEBUG] DeepSeekAnalyzer initialization - API Key: {self.api_key}")
        print(f"[DEBUG] DeepSeekAnalyzer initialization - API URL: {self.api_url}")
    
    def analyze_package(self, filename, features, xgboost_result):
        """åˆ†æè½¯ä»¶åŒ…çš„å®‰å…¨æ€§"""
        try:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {self.api_key}'
            }
            
            prompt = self._build_analysis_prompt(filename, features, xgboost_result)
            
            data = {
                'model': 'deepseek-chat',
                'messages': [
                    {'role': 'system', 'content': 'You are a professional open source component security analysis expert.'},
                    {'role': 'user', 'content': prompt}
                ],
                'temperature': 0.3,
                'max_tokens': 2000
            }
            
            print(f"[DEBUG] about to send API request to: {self.api_url}")
            print(f"[DEBUG] headers: {headers}")
            print(f"[DEBUG] request data: {data}")
            
            response = requests.post(self.api_url, headers=headers, json=data, timeout=30)
            
            print(f"[DEBUG] API response status code: {response.status_code}")
            print(f"[DEBUG] API response headers: {dict(response.headers)}")
            print(f"[DEBUG] API response content: {response.text}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"[DEBUG] API returned JSON: {result}")
                
                if 'choices' in result and len(result['choices']) > 0:
                    analysis = result['choices'][0]['message']['content']
                    print(f"[DEBUG] extracted analysis content: {analysis}")
                    
                    parsed_result = self._parse_analysis(analysis, xgboost_result)
                    print(f"[DEBUG] parsed result: {parsed_result}")
                    return parsed_result
                else:
                    print(f"[DEBUG] API returned format exception: {result}")
                    return self._fallback_analysis(xgboost_result)
            else:
                print(f"[DEBUG] DeepSeek API error: {response.status_code} - {response.text}")
                return self._fallback_analysis(xgboost_result)
                
        except requests.exceptions.Timeout:
            print("[DEBUG] API request timeout")
            return self._fallback_analysis(xgboost_result)
        except requests.exceptions.RequestException as e:
            print(f"[DEBUG] API request exception: {e}")
            return self._fallback_analysis(xgboost_result)
        except Exception as e:
            print(f"[DEBUG] DeepSeek analysis exception: {e}")
            import traceback
            print(f"[DEBUG] exception stack: {traceback.format_exc()}")
            return self._fallback_analysis(xgboost_result)
    
    def _convert_markdown_to_friendly_text(self, markdown_text):
        """å°†markdownæ ¼å¼çš„åˆ†æç»“æœè½¬æ¢ä¸ºå‹å¥½çš„ä¸­æ–‡æ˜¾ç¤ºæ ¼å¼"""
        if not markdown_text:
            return "æš‚æ— åˆ†æç»“æœ"
        
        # ç§»é™¤markdownåˆ†éš”ç¬¦
        text = re.sub(r'^---+$', '', markdown_text, flags=re.MULTILINE)
        
        # è½¬æ¢æ ‡é¢˜
        text = re.sub(r'### ğŸ›¡ï¸ (.+)', r'ğŸ”’ \1', text)
        text = re.sub(r'#### (\d+ï¸âƒ£) (.+)', r'ğŸ“‹ \2', text)
        
        # è½¬æ¢è¡¨æ ¼ä¸ºæ›´å‹å¥½çš„æ ¼å¼
        def convert_table(match):
            table_content = match.group(0)
            # ç§»é™¤è¡¨æ ¼æ ‡è®°
            table_content = re.sub(r'\|.*\|.*\|.*\|', '', table_content)
            table_content = re.sub(r'\|-+\|', '', table_content)
            # æå–è¡¨æ ¼å†…å®¹å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
            lines = [line.strip() for line in table_content.split('\n') if line.strip() and '|' in line]
            result = []
            for line in lines:
                cells = [cell.strip() for cell in line.split('|') if cell.strip()]
                if len(cells) >= 3:
                    result.append(f"â€¢ {cells[0]}: {cells[1]} - {cells[2]}")
            return '\n'.join(result) if result else "æš‚æ— å…·ä½“ç‰¹å¾æ•°æ®"
        
        text = re.sub(r'\|.*\|.*\|.*\|[\s\S]*?\|.*\|.*\|.*\|', convert_table, text)
        
        # è½¬æ¢å…¶ä»–markdownæ ¼å¼
        text = re.sub(r'\*\*(.+?)\*\*', r'ã€\1ã€‘', text)  # ç²—ä½“
        text = re.sub(r'`(.+?)`', r'ã€Œ\1ã€', text)  # ä»£ç 
        text = re.sub(r'> (.+)', r'ğŸ’¡ \1', text)  # å¼•ç”¨
        
        # è½¬æ¢åˆ—è¡¨
        text = re.sub(r'^\s*-\s+(.+)$', r'â€¢ \1', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*(\d+)\.\s+(.+)$', r'\1. \2', text, flags=re.MULTILINE)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
        
        # æ·»åŠ ä¸­æ–‡è¯´æ˜
        text = text.replace('Judgment', 'åˆ¤æ–­ç»“æœ')
        text = text.replace('Confidence', 'ç½®ä¿¡åº¦')
        text = text.replace('Risk score', 'é£é™©åˆ†æ•°')
        text = text.replace('Malicious', 'æ¶æ„')
        text = text.replace('Benign', 'è‰¯æ€§')
        text = text.replace('High', 'é«˜é£é™©')
        text = text.replace('Medium', 'ä¸­é£é™©')
        text = text.replace('Low', 'ä½é£é™©')
        text = text.replace('Risk level', 'é£é™©ç­‰çº§')
        text = text.replace('Main risk points', 'ä¸»è¦é£é™©ç‚¹')
        text = text.replace('Security suggestions', 'å®‰å…¨å»ºè®®')
        text = text.replace('Suggestion', 'å»ºè®®')
        text = text.replace('Note', 'æ³¨æ„')
        text = text.replace('This report is generated automatically by AI', 'æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ')
        text = text.replace('please combine manual security review', 'è¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥')
        
        return text.strip()
    
    def _build_analysis_prompt(self, filename, features, xgboost_result):
        # æå–å…³é”®ç‰¹å¾ç”¨äºåˆ†æ
        key_features = {
            'file_size': features.get('file_size', 'N/A'),
            'Number of Words in source code': features.get('Number of Words in source code', 'N/A'),
            'Number of lines in source code': features.get('Number of lines in source code', 'N/A'),
            'Number of base64 chunks in source code': features.get('Number of base64 chunks in source code', 'N/A'),
            'Number of IP adress in source code': features.get('Number of IP adress in source code', 'N/A'),
            'Number of sospicious token in source code': features.get('Number of sospicious token in source code', 'N/A'),
            'shannon mean ID source code': features.get('shannon mean ID source code', 'N/A'),
            'shannon max ID source code': features.get('shannon max ID source code', 'N/A'),
            'plus ratio max': features.get('plus ratio max', 'N/A'),
            'eq ratio max': features.get('eq ratio max', 'N/A'),
            'bracket ratio max': features.get('bracket ratio max', 'N/A'),
        }
        # ä¿®å¤ï¼šç”Ÿæˆç‰¹å¾æ‘˜è¦
        feature_summary = '\n'.join([f'- {k}: {v}' for k, v in key_features.items()])

        prompt = f"""
è¯·ä½œä¸ºä¸“ä¸šçš„å¼€æºç»„ä»¶å®‰å…¨åˆ†æä¸“å®¶ï¼Œç»“åˆä¸‹æ–¹è¯¦ç»†ç‰¹å¾æ•°æ®ï¼Œåˆ†æè¯¥åŒ…å¯èƒ½å­˜åœ¨çš„å®‰å…¨é£é™©ã€æ¶æ„è¡Œä¸ºæˆ–å¯ç–‘ç‚¹ï¼Œå¹¶è¯´æ˜ç†ç”±ï¼š

- æ–‡ä»¶åï¼š{filename}
- ä¸»è¦ç‰¹å¾æ•°æ®ï¼ˆä»…å±•ç¤ºéƒ¨åˆ†ï¼‰ï¼š
{feature_summary}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š

### 1ï¸âƒ£ æ¶æ„ç±»å‹åˆ¤æ–­
- **ç±»å‹**ï¼šè¯·æ ¹æ®ç‰¹å¾å’Œåˆ†æï¼Œåˆ¤æ–­è¯¥åŒ…æœ€å¯èƒ½å±äºå“ªç±»æ¶æ„ç±»å‹ï¼ˆå¦‚"ä¿¡æ¯çªƒå–"ã€"è¿œç¨‹æ§åˆ¶"ã€"ä¾èµ–æ··æ·†"ã€"æŒ–çŸ¿è„šæœ¬"ã€"åé—¨æœ¨é©¬"ç­‰ï¼‰ï¼Œå¦‚æ— æ˜æ˜¾æ¶æ„å¯å†™"æ— æ˜æ˜¾æ¶æ„"
- **ç†ç”±**ï¼šè¯·ç”¨ç®€æ˜ä¸­æ–‡è¯´æ˜åˆ¤æ–­ä¾æ®ï¼Œéœ€ç»“åˆç‰¹å¾å€¼ï¼ˆå¦‚"å‘ç°å¤§é‡base64ç¼–ç ï¼Œä¸”å­˜åœ¨å¯ç–‘ç½‘ç»œè¯·æ±‚ï¼Œç–‘ä¼¼ä¿¡æ¯çªƒå–"ï¼‰

### 2ï¸âƒ£ ä¸»è¦å¯ç–‘ç‰¹å¾ï¼ˆTop 5ï¼‰
| ç‰¹å¾åç§° | æ•°å€¼ | æè¿°/é£é™©ç‚¹ |
|---|---|---|
| ç¤ºä¾‹ï¼šç†µå‡å€¼ | 0.72 | ä»£ç æ··æ·†ã€å˜é‡åå¼‚å¸¸ |
| ... | ... | ... |

### 3ï¸âƒ£ é£é™©ç­‰çº§è¯„ä¼°
- **é£é™©ç­‰çº§**ï¼šé«˜/ä¸­/ä½
- **ä¸»è¦é£é™©ç‚¹**ï¼š1. ... 2. ...

### 4ï¸âƒ£ å®‰å…¨å»ºè®®
- å»ºè®®1ï¼š...
- å»ºè®®2ï¼š...

> **æ³¨æ„**ï¼šæ‰€æœ‰å†…å®¹è¯·ç”¨ä¸­æ–‡è¾“å‡ºï¼Œç»“æ„åŒ–å±•ç¤ºï¼Œä¾¿äºäººå·¥å¤æ ¸ã€‚

---
**ã€é‡è¦ã€‘** å¦‚æœä½ åˆ¤æ–­è¯¥åŒ…ä¸ºæ¶æ„æˆ–å­˜åœ¨é«˜é£é™©ï¼Œè¯·åœ¨ä¸‹æ–¹é¢å¤–æä¾›ä¸€ä¸ªJSONä»£ç å—ï¼ŒåŒ…å«è¯¦ç»†çš„æ¶æ„ä»£ç åˆ†æã€‚å¦‚æœæ— æ˜æ˜¾å¯ç–‘ä»£ç åˆ™è¿”å›ä¸€ä¸ªåŒ…å«ç©ºå­—ç¬¦ä¸²çš„JSONã€‚æ ¼å¼å¦‚ä¸‹ï¼š
```json
{{
  "code_location": "æ¶æ„ä»£ç æ‰€åœ¨çš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ /lib/core.js",
  "malicious_action": "å¯¹æ¶æ„è¡Œä¸ºçš„æ€»ç»“ï¼Œä¾‹å¦‚ï¼šé€šè¿‡å¼‚æˆ–è¿ç®—è§£ç base64å†…å®¹å¹¶åŠ¨æ€æ‰§è¡Œ",
  "technical_details": "å¯¹é‡‡ç”¨çš„æŠ€æœ¯æ‰‹æ³•çš„æ€»ç»“ï¼Œä¾‹å¦‚ï¼šé‡‡ç”¨å¤šå±‚æ··æ·†(base64+å¼‚æˆ–ç¼–ç +åŠ¨æ€æ‰§è¡Œ)",
  "malicious_code_snippet": "æœ€å…³é”®çš„å¯ç–‘ä»£ç ç‰‡æ®µï¼ˆ5-10è¡Œï¼‰"
}}
```
"""

        # è¿½åŠ ç»“æ„åŒ–Markdownæ ¼å¼è¦æ±‚
        prompt += f'''
---
### ğŸ›¡ï¸ å¼€æºç»„ä»¶å®‰å…¨åˆ†ææŠ¥å‘Š: {filename}

#### 1ï¸âƒ£ XGBooståˆ¤æ–­ç»“æœ
- **åˆ¤æ–­ç»“æœ**ï¼š{'æ¶æ„' if xgboost_result.get('prediction', 0) == 1 else 'è‰¯æ€§'}
- **ç½®ä¿¡åº¦**ï¼š{xgboost_result.get('confidence', 0.0) * 100:.2f}%
- **é£é™©åˆ†æ•°**ï¼š{xgboost_result.get('risk_score', 0.0):.3f}

#### 2ï¸âƒ£ ä¸»è¦å¯ç–‘ç‰¹å¾ï¼ˆTop 5ï¼‰
è¯·ç”¨ä¸‹è¡¨å±•ç¤ºæœ€å¯ç–‘çš„5ä¸ªç‰¹å¾ï¼š

| ç‰¹å¾åç§° | æ•°å€¼ | æè¿°/é£é™©ç‚¹ |
|---|---|---|
| ç¤ºä¾‹ï¼šç†µå‡å€¼ | 0.72 | ä»£ç æ··æ·†ã€å˜é‡åå¼‚å¸¸ |
| ... | ... | ... |

#### 3ï¸âƒ£ é£é™©ç­‰çº§è¯„ä¼°
- **é£é™©ç­‰çº§**ï¼šé«˜/ä¸­/ä½
- **ä¸»è¦é£é™©ç‚¹**ï¼š
  1. ...
  2. ...

#### 4ï¸âƒ£ å®‰å…¨å»ºè®®
- å»ºè®®1ï¼š...
- å»ºè®®2ï¼š...

#### 5ï¸âƒ£ æ¶æ„åŒ…ç±»å‹åˆ¤æ–­
- ç±»å‹ï¼šè¯·æ ¹æ®ç‰¹å¾å’Œåˆ†æï¼Œåˆ¤æ–­è¯¥åŒ…æœ€å¯èƒ½å±äºå“ªç±»æ¶æ„ç±»å‹ï¼ˆå¦‚"ä¿¡æ¯çªƒå–"ã€"è¿œç¨‹æ§åˆ¶"ã€"ä¾èµ–æ··æ·†"ã€"æŒ–çŸ¿è„šæœ¬"ã€"åé—¨æœ¨é©¬"ç­‰ï¼‰ï¼Œå¦‚æ— æ˜æ˜¾æ¶æ„å¯å†™"æ— æ˜æ˜¾æ¶æ„"
- ç†ç”±ï¼šè¯·ç”¨ä¸€å¥è¯è¯´æ˜åˆ¤æ–­ä¾æ®

---

> **æ³¨æ„**ï¼šæœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œè¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥ã€‚

è¯·ä¸¥æ ¼ä½¿ç”¨Markdownåˆ†çº§æ ‡é¢˜ï¼ˆ###ã€####ï¼‰ã€è¡¨æ ¼ã€åˆ—è¡¨ã€åŠ ç²—ç­‰ç»“æ„åŒ–æ ¼å¼ï¼Œé¿å…è¾“å‡ºå¤§æ®µæ— ç»“æ„æ–‡æœ¬ã€‚æ‰€æœ‰å†…å®¹è¯·ç”¨ä¸­æ–‡è¾“å‡ºã€‚'''
        return prompt
    
    def _parse_analysis(self, analysis_text, xgboost_result=None):
        """(Robustly)è§£æLLMçš„åˆ†æç»“æœï¼Œå¹¶æå–æ‰€æœ‰ç›¸å…³å­—æ®µ"""
        print("-" * 80)
        print("[RAW AI RESPONSE]:")
        print(analysis_text)
        print("-" * 80)

        # Initialize defaults
        malicious_code_info = {
            "code_location": "", "malicious_action": "", "technical_details": "", "malicious_code_snippet": ""
        }
        mal_type = 'æœªçŸ¥'
        mal_reason = 'æ— '
        risk_level = 'æœªçŸ¥'
        risk_points = 'AIæœªæä¾›è¯¦ç»†é£é™©ç‚¹'
        advice_list = []
        top_features = []
        
        # 1. Extract JSON blob first
        try:
            match = re.search(r'```json\s*(\{.*?\})\s*```', analysis_text, re.DOTALL)
            if match:
                json_str = match.group(1)
                data = json.loads(json_str)
                malicious_code_info["code_location"] = data.get("code_location", "")
                malicious_code_info["malicious_action"] = data.get("malicious_action", "")
                malicious_code_info["technical_details"] = data.get("technical_details", "")
                malicious_code_info["malicious_code_snippet"] = data.get("malicious_code_snippet", "")
                analysis_text = analysis_text.replace(match.group(0), "")
        except (json.JSONDecodeError, IndexError) as e:
            print(f"[DEBUG] Failed to parse malicious code snippet JSON: {e}")

        # 2. Split analysis text into sections for robust parsing
        sections = re.split(r'###\s*', analysis_text)
        
        for section in sections:
            section_title = section.split('\n')[0].strip()

            # Parse "æ¶æ„ç±»å‹åˆ¤æ–­" section
            if 'æ¶æ„ç±»å‹åˆ¤æ–­' in section_title:
                type_match = re.search(r'\*\*?ç±»å‹\*\*?\s*[:ï¼š]\s*(.+)', section)
                if type_match: mal_type = type_match.group(1).strip()
                
                reason_match = re.search(r'\*\*?ç†ç”±\*\*?\s*[:ï¼š]\s*(.+)', section)
                if reason_match: mal_reason = reason_match.group(1).strip()

            # Parse "ä¸»è¦å¯ç–‘ç‰¹å¾" section
            elif 'ä¸»è¦å¯ç–‘ç‰¹å¾' in section_title:
                rows = re.findall(r'\|\s*(.*?)\s*\|\s*(.*?)\s*\|\s*(.*?)\s*\|', section)
                for name, value, desc in rows:
                    name, value, desc = name.strip(), value.strip(), desc.strip()
                    if 'ç‰¹å¾åç§°' not in name and '---' not in name and name:
                        top_features.append({'name': name, 'value': value, 'desc': desc})
            
            # Parse "é£é™©ç­‰çº§è¯„ä¼°" section
            elif 'é£é™©ç­‰çº§è¯„ä¼°' in section_title:
                level_match = re.search(r'\*\*?é£é™©ç­‰çº§\*\*?\s*[:ï¼š]\s*(é«˜|ä¸­|ä½)', section)
                if level_match: 
                    chinese_level = level_match.group(1).strip()
                    # å°†ä¸­æ–‡é£é™©ç­‰çº§è½¬æ¢ä¸ºè‹±æ–‡
                    if chinese_level == 'é«˜':
                        risk_level = 'high'
                    elif chinese_level == 'ä¸­':
                        risk_level = 'medium'
                    elif chinese_level == 'ä½':
                        risk_level = 'low'
                    else:
                        risk_level = 'unknown'

                points_match = re.search(r'\*\*?ä¸»è¦é£é™©ç‚¹\*\*?\s*[:ï¼š]([\s\S]*)', section)
                if points_match: 
                    risk_points = points_match.group(1).strip()
            
            # Parse "å®‰å…¨å»ºè®®" section
            elif 'å®‰å…¨å»ºè®®' in section_title:
                advice_text_match = re.search(r'å®‰å…¨å»ºè®®\s*[:ï¼š]([\s\S]*)', section)
                if advice_text_match:
                    advice_text = advice_text_match.group(1).strip()
                    advice_list = [adv.strip('- ').strip() for adv in advice_text.split('\n') if adv.strip() and not adv.strip().isspace()]

        # Combine final result
        risk_explanation = f"é£é™©ç­‰çº§: {risk_level}\nä¸»è¦é£é™©ç‚¹:\n{risk_points}"

        final_result = {
            'risk_level': risk_level,
            'confidence': xgboost_result.get('confidence', 0.5),
            'type': mal_type,
            'reason': mal_reason,
            'top_features': top_features,
            'risk_points': risk_points,
            'advice_list': advice_list,
            'raw_analysis': analysis_text,
            'risk_explanation': risk_explanation,
            'llm_result': self._convert_markdown_to_friendly_text(analysis_text)
        }
        final_result.update(malicious_code_info)
        
        return final_result
    
    def _fallback_analysis(self, xgboost_result):
        """åœ¨APIè°ƒç”¨å¤±è´¥æˆ–è¶…æ—¶çš„æƒ…å†µä¸‹ï¼Œæä¾›åŸºäºXGBoostçš„å¤‡ç”¨åˆ†æç»“æœ"""
        print("[DEBUG] using fallback analysis")
        
        # æ ¹æ®XGBoostç»“æœç”Ÿæˆåˆ†ææ–‡æœ¬
        if xgboost_result.get('prediction', 0) == 1:
            analysis_text = f"""ğŸ”’ å¼€æºç»„ä»¶å®‰å…¨åˆ†ææŠ¥å‘Š

ğŸ“‹ XGBooståˆ¤æ–­ç»“æœ
â€¢ åˆ¤æ–­ç»“æœï¼šæ¶æ„
â€¢ ç½®ä¿¡åº¦ï¼š{xgboost_result.get('confidence', 0.0) * 100:.2f}%
â€¢ é£é™©åˆ†æ•°ï¼š{xgboost_result.get('risk_score', 0.0):.3f}

ğŸ“‹ ä¸»è¦é£é™©ç‚¹
â€¢ æœºå™¨å­¦ä¹ æ¨¡å‹è¯†åˆ«ä¸ºé«˜é£é™©ç»„ä»¶
â€¢ å»ºè®®è¿›è¡Œè¿›ä¸€æ­¥çš„äººå·¥å®¡æŸ¥ä»¥ç¡®è®¤æ˜¯å¦å­˜åœ¨æ¶æ„ä»£ç æˆ–å®‰å…¨æ¼æ´

ğŸ“‹ å®‰å…¨å»ºè®®
â€¢ ç«‹å³åœæ­¢ä½¿ç”¨è¯¥ç»„ä»¶
â€¢ æ£€æŸ¥å·²éƒ¨ç½²çš„åº”ç”¨æ˜¯å¦å—å½±å“
â€¢ å¯»æ‰¾å®‰å…¨çš„æ›¿ä»£ç»„ä»¶
â€¢ å°†è¯¥ç»„ä»¶æŠ¥å‘Šç»™ç›¸åº”çš„åŒ…ç®¡ç†å¹³å°

ğŸ’¡ æ³¨æ„ï¼šæœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œè¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥"""
            risk_level = 'high'
        else:
            analysis_text = f"""ğŸ”’ å¼€æºç»„ä»¶å®‰å…¨åˆ†ææŠ¥å‘Š

ğŸ“‹ XGBooståˆ¤æ–­ç»“æœ
â€¢ åˆ¤æ–­ç»“æœï¼šè‰¯æ€§
â€¢ ç½®ä¿¡åº¦ï¼š{xgboost_result.get('confidence', 0.0) * 100:.2f}%
â€¢ é£é™©åˆ†æ•°ï¼š{xgboost_result.get('risk_score', 0.0):.3f}

ğŸ“‹ å®‰å…¨è¯„ä¼°
â€¢ æœºå™¨å­¦ä¹ æ¨¡å‹åˆ†ææ˜¾ç¤ºè¯¥ç»„ä»¶åŒ…ç›¸å¯¹å®‰å…¨
â€¢ æœªå‘ç°æ˜æ˜¾çš„æ¶æ„è¡Œä¸ºæˆ–å®‰å…¨æ¼æ´

ğŸ“‹ å®‰å…¨å»ºè®®
â€¢ å»ºè®®å®šæœŸæ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ä»¥ç¡®ä¿å®‰å…¨
â€¢ ä¿æŒå¯¹ç»„ä»¶åŒ…çš„æŒç»­ç›‘æ§
â€¢ å…³æ³¨å®˜æ–¹å®‰å…¨å…¬å‘Š

ğŸ’¡ æ³¨æ„ï¼šæœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œè¯·ç»“åˆäººå·¥å®‰å…¨å®¡æŸ¥"""
            risk_level = 'low'
        
        return {
            'risk_level': risk_level,
            'confidence': xgboost_result.get('confidence', 0.5),
            'analysis': analysis_text,
            'raw_analysis': analysis_text,
            'recommendation': 'å»ºè®®ç»“åˆäººå·¥å®¡æŸ¥å’Œå®šæœŸå®‰å…¨æ›´æ–°'
        }