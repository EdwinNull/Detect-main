# 开源包抓取功能使用说明

## 为什么Web界面中没有包抓取功能？

您运行的是**Web检测应用**，它只提供包的安全检测功能。包抓取功能是**独立的命令行工具**，用于从开源仓库获取包进行检测。

## 包抓取工具功能

我为您创建了一个完整的包抓取工具 `package_crawler.py`，支持：

### ✅ 功能特性
- **NPM包抓取**: 从npmjs.com获取最新包
- **PyPI包抓取**: 从PyPI获取Python包
- **自动下载**: 使用npm pack和pip download命令
- **数据库集成**: 自动保存到检测系统数据库
- **去重功能**: 避免重复下载相同包
- **批量处理**: 支持指定下载数量

### 📁 文件结构
```
Detect-main/
├── package_crawler.py          # 包抓取工具
├── downloads/                  # 下载目录
│   ├── npm/                   # NPM包存储
│   └── pypi/                  # PyPI包存储
└── 包抓取使用说明.md           # 本说明文档
```

## 使用方法

### 1. 安装依赖
```bash
# 确保已安装npm和pip
npm --version
pip --version
```

### 2. 运行抓取工具

#### 抓取NPM包
```bash
# 抓取5个最新NPM包
python package_crawler.py npm 5

# 抓取10个NPM包
python package_crawler.py npm 10
```

#### 抓取PyPI包
```bash
# 抓取5个Python包
python package_crawler.py pypi 5

# 抓取10个Python包
python package_crawler.py pypi 10
```

#### 查看已下载的包
```bash
# 列出所有已下载的包
python package_crawler.py list
```

#### 默认抓取（NPM和PyPI各5个）
```bash
# 不传参数，默认抓取
python package_crawler.py
```

### 3. 在Web界面中查看

抓取完成后，您可以在Web界面中看到这些包：

1. **启动Web应用**:
   ```bash
   python run.py
   ```

2. **访问检测历史**:
   - 登录系统
   - 点击"检测历史"
   - 查看抓取的包记录

3. **进行安全检测**:
   - 选择抓取的包
   - 点击"重新检测"
   - 查看检测结果

## 示例输出

```
=== 开源包抓取工具 ===
下载目录: D:\xiazai\Detect-main\downloads
数据库: D:\xiazai\Detect-main\security_scanner.db

开始抓取npm包，限制数量: 5
找到 5 个npm包
[1/5] 下载: express@4.18.2
  ✓ 下载成功: express-4.18.2.tgz
  ✓ 已保存到数据库
[2/5] 下载: lodash@4.17.21
  ✓ 下载成功: lodash-4.17.21.tgz
  ✓ 已保存到数据库
...

开始抓取PyPI包，限制数量: 5
[1/5] 下载: requests
  ✓ 下载成功: requests-2.31.0.tar.gz
  ✓ 已保存到数据库
[2/5] 下载: numpy
  ✓ 下载成功: numpy-1.24.3.tar.gz
  ✓ 已保存到数据库
...

=== 已下载的包 ===

NPM包 (5个):
  - express-4.18.2.tgz
  - lodash-4.17.21.tgz
  - axios-1.6.2.tgz
  - moment-2.29.4.tgz
  - chalk-4.1.2.tgz

PyPI包 (5个):
  - requests-2.31.0.tar.gz
  - numpy-1.24.3.tar.gz
  - pandas-2.0.3.tar.gz
  - flask-2.3.3.tar.gz
  - django-4.2.7.tar.gz

=== 抓取完成 ===
您可以在Web界面中查看和检测这些包
```

## 高级功能

### 定时抓取
您可以设置定时任务，定期抓取新包：

```bash
# Windows计划任务
schtasks /create /sc daily /tn "PackageCrawler" /tr "python D:\xiazai\Detect-main\package_crawler.py" /st 09:00

# Linux crontab
0 9 * * * cd /path/to/Detect-main && python package_crawler.py
```

### 自定义包列表
您可以修改脚本中的包列表：

```python
# 在crawl_pypi_packages方法中修改
popular_packages = [
    "your-package-1", "your-package-2", "your-package-3"
]
```

### 批量检测
抓取完成后，可以批量进行安全检测：

```python
# 在Web界面中批量选择包进行检测
# 或者编写脚本自动检测所有pending状态的包
```

## 注意事项

### ⚠️ 重要提醒
1. **网络连接**: 确保网络连接稳定
2. **存储空间**: 包文件可能较大，注意磁盘空间
3. **下载限制**: 避免过于频繁的请求，建议间隔1秒以上
4. **包质量**: 抓取的包质量取决于源仓库

### 🔧 故障排除
1. **npm命令失败**: 确保已安装Node.js和npm
2. **pip命令失败**: 确保已安装Python和pip
3. **网络超时**: 检查网络连接，增加超时时间
4. **权限问题**: 确保有写入下载目录的权限

## 总结

现在您有了完整的包抓取功能：

1. **命令行工具**: `package_crawler.py` 用于抓取包
2. **Web检测系统**: `run.py` 用于检测包安全性
3. **完整流程**: 抓取 → 检测 → 分析 → 报告

这样您就可以：
- 自动获取最新的开源包
- 进行安全检测和分析
- 建立自己的包安全数据库
- 持续监控开源包的安全状况

开始使用吧！🚀 